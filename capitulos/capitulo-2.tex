\chapter{Liquid State Theory}
\label{Cap2}

In this chapter, a brief description of Liquid State Theory is carried out. In particular, 
the focus of the chapter is to state what a liquid is, its thermodynamical properties and
how equilibrium statistical mechanics is used to understand them. Then, a description of 
the hard-sphere fluid is mentioned, which is the fundamental system studied in this work.
After this, a brief description of computer simulation methods is outlined, both
Molecular Dynamics and Monte Carlo methods are mentioned, giving more importance to
Monte Carlo methods which are extensively used in this work.
The chapter is closed with a presentation of the important formalism that is the 
Ornstein-Zernike integral equation. Its important aspects are mentioned, along with
a discussion of several closure relations and the important role of the
\emph{bridge function.}

\section{Equilibrium Statistical Mechanics}
\label{sec:eq-statmech}

Consider a system of $N$ spherical particles in three dimensions
where each particle is characterized by its position $\vecr$ and momentum $\vecp$.
The \emph{Hamiltonian} of the system is given by
\begin{equation}
    \mathcal{H} \left( \vecr^{N}, \vecp^{N} \right) = 
    K \left( \vecp \right) + U \left( \vecr \right)
    \label{eq:hamiltonian}
\end{equation}
with $K$ the kinetic energy and $U$ the potential energy of the system.
All together, the 6$N$ variables define a \emph{phase point} in a 6$N$-dimensional
\emph{phase space}. The state point is then described by a
\emph{phase space vector} $\Gamma \left( \vecr, \vecp \right)$, however, considering that all
$N$ particles move according to Newton's equations of motion, $\Gamma$ is
a function of time, or $\Gamma(t)$. Using this phase space vector, \emph{time averages}
can be obtained for a given observable $A$ by means of the following expression
\begin{equation}
    \left< A \right> = \lim_{t \to \infty} \frac{1}{t} 
    \int_{0}^{t} A \: \Gamma(t') \: dt' \, .
    \label{eq:time-average}
\end{equation}
If instead the complete set of state points, also known as the \emph{ensemble} of state
points, is considered, then the average $\left< A \right>$ can be rewritten in
terms of this ensemble.
This ensemble of state points is distributed in phase space according to a probability 
distribution that is specified by the \emph{thermodynamic ensemble.} Then, if the time 
evolution of $\Gamma(t)$ is such that all states are visited eventually, irrespective of 
its initial conditions, the system satisfies the weak ergodic
theorem~\cite{kittelElementaryStatisticalPhysics2004},
and the time average in \autoref{eq:time-average} can then be rewritten with an
\emph{ensemble average} that reads
\begin{equation}
    \left< A \right> = \sum_{\Gamma} A(\Gamma) \: \rho_{ens} (\Gamma)
    \: ,
    \label{eq:ensemble-average}
\end{equation}
where the sum is for all state point vectors $\Gamma$ and $\rho_{ens} (\Gamma)$
is the probability density function for the ensemble. This probability function is
a weight function for the averaging procedure and should be normalized,
\begin{equation}
    \sum_{\Gamma} \rho_{ens} (\Gamma) = 1 \, .
    \label{eq:normalized}
\end{equation}
With this information, it is now time to introduce the \emph{canonical ensemble}, which
is the main ensemble used throughout this work.

\subsection{Canonical ensemble}
The canonical ensemble is established as a system of $N$ particles in a fixed volume $V$
at temperature $T$ that can exchange energy with a heat bath. This ensemble has a
probability density function associated with it,
\begin{equation}
    \rho_{NVT} = \frac{e^{-\beta \mathcal{H}(\Gamma)}}{\sum_{\Gamma} e^{-\beta \mathcal{H}(\Gamma)}}
    \: ,
    \label{eq:canonical-density}
\end{equation}
where $\beta=1/k_{B} T$, and with $k_{B}$ being the Boltzmann's constant. 
In the classical limit of continuous distribution functions, the denominator from 
\autoref{eq:canonical-density} transforms into
\begin{equation}
    Q(N,V,T) = \frac{1}{N! \, h^{3N}} \int d \vecp^{N} \, d \vecr^{N} \,
    e^{- \beta \mathcal{H} \left( \vecr^N, \vecp^N \right)}
    \: ,
    \label{eq:canonical-partition}
\end{equation}
which is known as the \emph{canonical partition function}~\cite{huangStatisticalMechanics1987}.
Here, $h$ is an arbitrary but predetermined constant with the units of energy $\times$
time. As a side note, in the original formulation by Gibbs, the value of $h$ was set
to $h=1$~\cite{gibbsElementaryPrinciplesStatistical2014}, however, since the advent
of quantum mechanics, it is now taken to be Planck's constant~\cite{tolmanPrinciplesStatisticalMechanics1979}
in order to show a correspondence between the classical and quantum formulations.
Indeed, the integrals from \autoref{eq:canonical-partition} can be separated, and the
integral over the momentum coordinates can be carried out analytically giving,
\begin{equation}
    Q(N,V,T) = \frac{1}{N! \, \Lambda^{3N}} \int d \vecr^{N} \,
    e^{- \beta U \left( \vecr^N \right)}
    \: ,
    \label{eq:canonical-partition-position}
\end{equation}
with $\Lambda=\sqrt{h^2 / 2 \pi m k_{B} T}$ the thermal wavelength, also known as the
\emph{de Broglie} wavelength. This again shows a correspondence between classical
and quantum formulations. The remaining integral over the positions is called the
\emph{configuration integral},
\begin{equation}
    Z(N,V,T) = \int d \vecr^{N} \, e^{- \beta U \left( \vecr^N \right)} \, .
    \label{eq:configuration-int}
\end{equation}
Finally, we arrive at the canonical ensemble density function in the continuum limit
which is
\begin{equation}
    \rho_{NVT} = \frac{e^{- \beta U(\vecr^{N})}}{Z(N,V,T)} \, .
    \label{eq:canonical-limit}
\end{equation}
Using this probability density function, the ensemble average for an observable $A$ is
computed as
\begin{equation}
    \left< A \right> = \frac{\int e^{- \beta U(\vecr^{N})} \, A(\vecr^{N}) \, d \vecr^{N}}{Z(N,V,T)} \, .
    \label{eq:average-canonical}
\end{equation}

\section{Distribution functions}

Still, the probability density function in \autoref{eq:canonical-limit} provides far more
information from the system than necessary for the calculation of thermodynamical functions
and structure properties. Instead, a focus on a small set of particles $n \ll N$ is 
preferred, in which case a \emph{reduced probability density} is defined as
\begin{equation}
    \rho^{(n)}_{N} (\vecr^{n}) \coloneqq \frac{N!}{(N-n)!} \frac{1}{Z(N,V,T)}
    \int e^{- \beta U(\vecr^{N})} \, d \vecr^{(N-n)} \; ,
    \label{eq:reduced-canonical}
\end{equation}
where $\rho^{(n)}_{N} (\vecr^{n})$ is also known as the equilibrium 
$n$\emph{-particle density}.
The quantity $\rho^{(n)}_{N} (\vecr^{n}) \, d \vecr^{n}$ defines the probability of finding
$n$ particles of the system with coordinates in a volume element $d \vecr^{n}$ from the
phase space, regardless the positions and momenta of the remaining particles.
As a result of this contraction of the probability density function, it is now possible to
provide a complete description of the \emph{structure} of a fluid, while the knowledge
of low-order particle distribution functions is sufficient to calculate thermodynamic
quantities~\cite{mcquarrieStatisticalMechanics2000}.

From the definition of the $n$-particle density in \autoref{eq:reduced-canonical}, the
normalization condition is
\begin{equation}
    \int \rho^{(n)}_{N} (\vecr^{n}) \, d \vecr^{n} = \frac{N!}{(N-n)!} \; ,
    \label{eq:normalization-reduced}
\end{equation}
and in particular, the \emph{single-particle} density is
\begin{equation}
    \int \rho^{(1)}_{N} (\vecr) \, d \vecr = N \; ,
    \label{eq:single-particle-density}
\end{equation}
For a homogeneous fluid, \autoref{eq:single-particle-density} is then simplified
to the following expression
\begin{equation}
    \rho^{(1)}_{N} = N / V \equiv \rho
    \label{eq:homogeneous-density}
\end{equation}
where $\rho$ is the \emph{particle number density}.

The $n$-particle distribution function $g^{(n)}_{N} (\vecr^{(n)})$ is defined in terms
of the particle densities by
\begin{equation}
    g^{(n)}_{N} (\vecr^{(n)}) \coloneqq \frac{\rho^{(n)}_{N} (\vecr_{1}, \dots , \vecr_{n})}
    {\prod_{i=1}^{n} \rho^{(1)}_{N} (\vecr_{i})} \; ,
    \label{eq:gr-def}
\end{equation}
which again for a homogeneous fluid it reduces to
\begin{equation}
    \rho^{n} g^{(n)}_{N} (\vecr^{(n)}) = \rho^{(n)}_{N} (\vecr^{n}) \; .
    \label{eq:homogenous-gr}
\end{equation}
Particle distribution functions measure the extent to which the structure of a fluid 
deviates from complete randomness~\cite{hansenTheorySimpleLiquids2013}.
If the system is also isotropic, which it shall be the consideration henceforth,
the pair distribution function $g^{(2)}_{N} (\vecr_{1}, \vecr_{2})$ is a function only
of the separation $r = r_{12} = \lvert \vecr_{2} - \vecr_{1} \rvert$ between particles
in positions $\vecr_{1}$ and $\vecr_{2}$; here $\lvert \cdot \rvert$ is the Euclidean
distance or norm between two $n$-dimensional vectors.
The function $g^{(2)}_{N} (\vecr_{1}, \vecr_{2})$ is the
\emph{radial distribution function}, and it is referred to as 
\rdf for the rest of this work.
This radial distribution function is of crucial importance in Liquid State Theory for
several reasons. First, the radial distribution function can be obtained experimentally
for liquids using X-ray diffraction, digital video-microscopy, and light scattering
experiments~\cite{mcquarrieStatisticalMechanics2000}.
Second, thermodynamic properties of liquids can be determined using integrals that
contain the radial distribution function. Third, the radial distribution function can
be easily computed in computer simulations~\cite{allenComputerSimulationLiquids2017}, 
which is the standard way to obtain these quantities. Finally, the radial distribution
function can be obtained analytically using integral equations such as the Ornstein-Zernike
equation, which shall be discussed in a later section.

\section{Thermodynamic properties} \label{sec:thermodynamics}
As mentioned in the previous section, thermodynamic properties can be defined in terms of
distribution functions, and in particular, in terms of the radial distribution
function~\cite{hansenTheorySimpleLiquids2013}.
It is now time to discuss such expressions, and the relation between thermodynamical
quantities and the radial distribution function.

The \emph{total energy} $E$ of a three-dimensional system of $N$ particles can be defined 
in terms of the radial distribution function as
\begin{equation}
    E = E_{ideal} + E_{excess} = \frac{3 N k_{B} T}{2} +
    \frac{N}{2} \int_{0}^{\infty} \rho \, u(r) \, g(r) \, 4 \pi r^2 \, dr
    \, ,
    \label{eq:total-energy-rdf}
\end{equation}
where $E_{ideal}$ is the ideal gas contribution, whose result comes directly from
the energy equipartition theorem~\cite{mcquarrieStatisticalMechanics2000};
$E_{excess}$ is an interaction or excess contribution that can be understood
as the interaction energy between a central particle for all the $N$ particles,
and all the neighbors located in a spherical shell of radius $r$ and thickness
$dr$. The total number of neighbors is given by $4 \pi r^2 \rho g(r) \, dr$.
The integration from $0$ to $\infty$ gives all the interaction energy, and
the factor of $1/2$ accounts for double counting of particle pairs.
The function $u(r)$ is the \emph{pairwise interaction potential} which comes
from the fact that the total potential energy $U(\vecr^{N})$ can be expressed
in terms of the individual particle interactions as follows
\begin{equation}
    U(\vecr^{N}) = \sum_{i} u_{1} (\vecr_{i}^{N}) +
    \sum_{i} \sum_{j>i} u_{2} (\vecr_{i}^{N}, \vecr_{j}^{N}) +
    \dots
    \label{eq:pairwise-energy}
\end{equation}
These kind of interactions are the most commonly researched and studied, given that most
systems can be modeled after such interaction potentials, such as the
hard-sphere, Lennard-Jones, Yukawa~\cite{huangStatisticalMechanics1987}
and several others. The hard-sphere interaction potential will be discussed
in a later section.
In the current work, the two-particle interaction potential
$u_{2} (\vecr_{i}^{N}, \vecr_{j}^{N})$ is referred to simply as $u(r)$.
It is important to note that this is not the norm, and interaction potentials
that are not pairwise additive are also studied. These many-body potentials are
notoriously hard to study, but recent advances in Machine Learning have made it
possible to do so~\cite{boattiniModelingManybodyInteractions2020}.

The \emph{pressure equation} is a relation between the thermodynamic pressure
$P$ and the radial distribution function, defined for a three-dimensional system as:
\begin{equation}
    P=P_{ideal}+P_{excess}= \frac{\rho}{\beta} - \frac{2 \pi \beta \rho}{3}
    \int_{0}^{\infty} u'(r) \, g(r) \, r^3 \, dr \, ,
    \label{eq:pressure-equation}
\end{equation}
where $P_{ideal}$ is the kinetic pressure of an ideal gas, and $P_{excess}$
is the excess pressure that can be derived using classical mechanics through the
virial theorem~\cite{goldsteinClassicalMechanics2002}.

Another important quantity that must be mentioned is the
\emph{isothermal compressibility}. Its thermodynamic definition
is~\cite{mcquarrieStatisticalMechanics2000}
\begin{equation}
    \chi_{T} = - \, \frac{1}{V} { \left( \frac{\partial V}{\partial P} \right) }_{T} =
    \frac{1}{\rho} { \left( \frac{\partial \rho}{\partial P} \right) }_{T}
    \; ,
    \label{eq:isothermal-chi}
\end{equation}
and it is a physical measure of the relative change in volume due to a change
in pressure or stress.
It can also be computed using the radial distribution function using the following
expression~\cite{hansenTheorySimpleLiquids2013}
\begin{equation}
    \frac{\chi_{T} \, \beta}{\rho} = 1 + \rho \int d \vecr \, \left[ g(r) - 1 \right]
    \; .
    \label{eq:chi-rdf}
\end{equation}
We call this the \emph{compressibility equation}, and it is a standard way of computing
the isothermal compressibility.

\section{The hard-sphere model} \label{sec:hard-sphere}
In order to describe the behavior of materials, pairwise interaction potentials are chosen 
according to specific physical properties. These interaction potentials provide a 
particular functional form for the potential energy $U$ of the system.
With this information, all the theory described so far can be used to understand the
physical properties of the system, and compute thermodynamic quantities.

Out of all the possible interaction potentials, there is one that stands out for its
simplicity and surprising ability to generalize to complex systems. This model is
called the \emph{hard sphere model}, and shall be the topic of discussion for this
section.
The \emph{hard sphere model} is a simple pairwise interaction potential, defined as
\begin{equation}
    u_{hs} = 
    \begin{cases}
        \infty \, , &r < \sigma \\
        0 \, , &r \geq \sigma \; ,
    \end{cases}
    \label{eq:hard-sphere}
\end{equation}
where $\sigma$ is the diameter of the particles in the system, and $r$ is the distance
between the centers of two particles, as previously stated.

This interaction is a particular model; it is an approximation of the intrinsic
behavior of particles.
It attempts to describe the excluded volume interaction of particles, similar to what
happens with billiards balls in three dimensions.
These particles seem to hit each other only to be separated at the contact point, which
is the value of $\sigma$. Hence, this model is by definition a \emph{repulsive model}.
Apart from being a reference model system for the liquid
state~\cite{hansenTheorySimpleLiquids2013}, hard spheres are extremely useful in
colloid science, as mentioned in the introduction section. This is due to the fact
that it has been demonstrated that the hard sphere interaction gives rise to a
fluid-crystal phase transition around a volume fraction of 50\% of hard 
spheres~\cite{hooverMeltingTransitionCommunal1968a,gastSimpleOrderingComplex1998,roblesNoteEquationState2014a}.
This phase transition was the subject of an extensive discussion in the early
1950's and was for the first time discovered in computer
simulations~\cite{alderPhaseTransitionHard1957a}.
The relationship between this simple model and colloid science was discovered
experimentally by Pusey and van Megen~\cite{puseyPhaseBehaviourConcentrated1986},
in dense colloidal suspensions of sterically stabilized particles in a solvent.

In this work, a similar potential is used, though defined differently. Looking closely
at \autoref{eq:hard-sphere}, it is straightforward to see that the potential is a
discontinuous function. In mathematical proofs and statistical mechanics frameworks,
this poses no problem. It might be hard to manipulate, mathematically speaking,
but it is possible to do so. Yet, the problem lies with the use of computer simulations.
The technical issues arise mostly in Molecular and Brownian Dynamics computer
simulations~\cite{allenComputerSimulationLiquids2017}, so a different formulation
must be employed. Computer simulations of liquids are presented in the next section.
In 2018, Báez \emph{et al}~\cite{baezUsingSecondVirial2018} used the Extended Law
of Corresponding States~\cite{valadez-perezReversibleAggregationColloidal2018}
to map the second virial coefficient of the hard sphere model to a continuous
model. By doing so, most of the dynamic and thermodynamic properties of the hard sphere
model are "passed along" to the continuous function, which in turn is suited for all
kinds of computer simulation algorithms. This new continuous function is used
throughout this work, and it is defined as follows
\begin{equation}
    u_{CP} = 
    \begin{cases}
        A \, \epsilon \left[ {\left(\frac{\sigma}{r}\right)}^{\lambda} -
        {\left(\frac{\sigma}{r}\right)}^{\lambda - 1} \right] + \epsilon \, , 
        &r < \sigma \, B \, , \\
        \hspace{1.5cm} 0 \, , &r \geq \sigma \, B \, ,
    \end{cases}
    \label{eq:cont-hs}
\end{equation}
with
\begin{equation}
    A = \lambda {\left(\frac{\lambda}{\lambda -1}\right)}^{\lambda - 1} \, ,
    \quad
    B = \left(\frac{\lambda}{\lambda -1}\right) \, .
    \label{eq:ab-params}
\end{equation}
The value of $\lambda$ is fixed to $\lambda=50$, following the findings in the work of
Báez \emph{et al}~\cite{baezUsingSecondVirial2018}; and the value of $\epsilon$ is
not fixed explicitly, instead the reduced potential is employed, 
i.e., $u^{*}=u_{CP} / \epsilon$. It is also important to define a particular quantity,
the reduced temperature \(T^{*}=k_{B} T \, / \epsilon\), which used in the original work
by Báez \emph{et al} to ensure that the second virial coefficient is accurately reproduced.
This quantity is defined as,
\begin{equation}
    T^{*} = a + \frac{b}{\lambda^c}
    \label{eq:t-star}
\end{equation}
and for a three-dimensional system the parameters used are \(a=1.4543, b=1.199, 1.0545 .\)

\section{Computer simulations of liquids}

Liquid State Theory is always supplemented with results from computer simulations
because these methods come from first-principles Physics and yield accurate estimations
of the behavior of the physical systems. Also, given the availability of computational
resources nowadays, these methods have become a standard tool for research.
There has been an extensive amount of research in these computer simulation methods,
following the pioneering work of Alder and Wainwright~\cite{alderPhaseTransitionHard1957a}.
There are two main computer simulations methods used in Liquid State Theory and
Soft Matter research: \emph{Molecular Dynamics} and \emph{Monte Carlo methods}~\cite{allenComputerSimulationLiquids2017,frenkelUnderstandingMolecularSimulation2001}.
These methods serve different purposes, and because of that, a brief description of each
one will be outlined here. However, the main focus of this work is the use of
the Monte Carlo simulation technique. \emph{Brownian dynamics} methods are
equally as important to Soft Matter research, but they are beyond the scope of this work.
The book by Jan Dhont~\cite{dhontIntroductionDynamicsColloids1996} provides a rigorous
explanation of the Brownian dynamics framework.

\subsection{Molecular dynamics}
Molecular Dynamics simulations use the basic laws of Physics to understand the behavior
of liquids. In particular, Newton's laws are used to evolve a system of particles through
time and space. For a system of $N$ particles, each with mass $m_i$, $i=1,2,\dots,N$,
the equations of motion are
\begin{equation}
    \bm{F}_i (t) = m_i \frac{d^2 \vecr_i}{dt^2} \; ,
    \label{eq:newton}
\end{equation}
with
\begin{equation}
    \bm{F}_i (t) = - \nabla_{\vecr_i} U(\lvert \vecr_i - \vecr_j \rvert)
    , \quad U = \sum_{i} \sum_{j} u(\lvert \vecr_i - \vecr_j \rvert)
    \label{eq:newton-potential}
\end{equation}
the force on particle $i$ with position $r_i$ exerted by particle $j$ with position
$\vecr_j$, and $U$ the potential energy, which in the context of liquids this is the
interaction potential between the particles. In most cases, this interaction potential
can be modeled as the pairwise interaction between two particles.

To integrate these equations of motion, different integration schemes have been developed.
At first, Alder and Wainwright~\cite{alderPhaseTransitionHard1957a} used the simple
Euler method to integrate these equations. It was later understood that such scheme
does not yield \emph{stable} results, i.e., the integration scheme gives different results
if used with different initial conditions each time.
Integration methods must conserve important physical quantities, such as energy,
momentum and phase space properties~\cite{razafindralandyReviewGeometricIntegrators2018}.
The Verlet method was later introduced in 1967 by Loup Verlet~\cite{verletComputerExperimentsClassical1967a},
in order to alleviate the drawbacks of the Euler method. These methods are crucial to obtain
correct results from molecular dynamics computer simulations.

The main appeal of molecular dynamics computer simulations is the fact that
\emph{dynamical quantities} can be computed effortlessly, given the temporal nature 
of the formulation. Physical observables such
as the \emph{mean square displacement} and the \emph{dynamic structure factor}~\cite{dhontIntroductionDynamicsColloids1996,hansenTheorySimpleLiquids2013}
are of great importance to the understanding of transport properties in liquids and
more complex systems in Soft Matter.

\subsection{Monte Carlo methods}
Monte Carlo methods make use of randomness to explore a possible solution to a
given problem. The basic idea is to exploit random sampling to obtain numerical
results. Monte Carlo methods have successfully been applied to
three main problems: optimization, numerical integration, and probability density
function estimation~\cite{kroeseWhyMonteCarlo2014}. It might seem odd that Statistical
Physics is not mentioned here, but the reason for that is that it actually belongs to
the wider range of probability density function estimation techniques. It is the
purpose of this section to explore Monte Carlo methods and their application to
the simulation of liquids, mainly because this is the method used in this
work, and because in this work there is no dynamical physical quantity involved,
only statical ones, i.e., the radial distribution function.

The basic idea of Monte Carlo methods in the computer simulation of liquids is to
generate a sequence of configurations for a given system. The idea is to arrive at a
probability distribution function close to the ensemble probability distribution
function chosen to model the fluid. For instance, if a system
is under the $NVT$ ensemble, the sequence of Monte Carlo steps are expected to converge
to the distribution function given by \autoref{eq:canonical-limit}. Having arrived at this
estimation, observables can the be computed, as in \autoref{eq:average-canonical}.
There is also other possibilities of ensemble distribution functions that can be
used with Monte Carlo computer simulations, such as the isobaric-isothermal ensemble
and the Gibbs ensemble~\cite{frenkelUnderstandingMolecularSimulation2001}.

In general, Monte Carlo methods are completely random. However, liquids cannot be
subjected to complete randomness due to their intermolecular interactions. In the case
of the hard sphere fluid, the denominator of \autoref{eq:canonical-limit} would be zero
at least 50\% of the time, which would incur in numerical instabilities and observables
would not get measured properly. So, a \emph{bias} must be introduced in order to
\emph{guide} the sequence of configurations to a path which could avoid unnecessary
configurations. This bias is called \emph{importance sampling}, and the most common rule,
as well as the one used here, is the Metropolis rule~\cite{landauGuideMonteCarlo2021}.
Nevertheless, when a bias is introduced, there is one important rule that must
\emph{always} be obeyed: the condition of \emph{detailed balance}. Detailed balance
is a strong condition stating that if there is a transition from a state $o$ to a
state $n$, this should be balanced with the number of accepted trial moves that go
from state $n$ to state $o$. This can also be summarized in mathematical form,
\begin{equation}
    p(o) \, T(o \Longrightarrow n) = p(n) \, T(n \Longrightarrow o) \, ,
    \label{eq:detailed-balance}
\end{equation}
where $p(\alpha)$ is the probability to be at state $\alpha$, and 
$T(\alpha \Longrightarrow \beta)$ denotes the probability to go from a state 
$\alpha$ to a state $\beta$. It might look like a simple rule, but this condition
is what guarantees the ergodicity of the computer
simulation~\cite{landauGuideMonteCarlo2021}, i.e., that the phase space is explored
correctly and with physical significance. If this condition is not met, the results
do not represent the physical properties of the system, and the observables cannot
be computed properly.

In the $NVT$ ensemble, the Metropolis rule that satisfies detailed balance is
\begin{equation}
    \frac{p(n)}{p(o)} = \frac{A(o \Longrightarrow n)}{A(n \Longrightarrow o)} =
    \exp{ \left\{ -\beta \left[U(n) - U(o)\right] \right\} }
    \; ,
    \label{eq:nvt-balance}
\end{equation}
with
\begin{equation}
    A(o \Longrightarrow n) = \min{ \left(1, \exp{ \left\{ -\beta \left[U(n) - U(o)\right] \right\} } \right)} 
    \; ,
    \label{eq:nvt-acceptance}
\end{equation}
the proof that this condition satisfies detailed balance is omitted here, but it can
be found in the book by Frenkel~\cite{frenkelUnderstandingMolecularSimulation2001}.
With this acceptance rule, it is guaranteed that the configurations that have the larger
Boltzmann factor, i.e. $\exp{ \left\{ -\beta \left[U(n) - U(o)\right] \right\} }$, 
will be visited more frequently rather than the configurations with a smaller
Boltzmann factor, which will be avoided.
In practice, the core of the Monte Carlo method for the computer simulation of liquids, 
which corresponds to the Metropolis rule, is implemented as follows:
\begin{itemize}
    \item Select a particle $i$ at random.
    \item Calculate the energy cost to move particle $i$.
    \item Move particle $i$ randomly.
    \item Calculate the new energy cost for having displaced a particle.
    \item Accept or reject the move according to \autoref{eq:nvt-balance} and \autoref{eq:nvt-acceptance}.
    \item Update the total energy configuration.
\end{itemize}
Monte Carlo methods are efficient when static quantities, such as the radial distribution
function, are computed. This is because time is not part of the computer simulation method,
unlike the previously discussed Molecular Dynamics method.
Monte Carlo methods can efficiently explore a large portion of the phase
space due to their stochastic nature. Although the phase space might be large, it is often
the case that a simple exploration of one or two replicas of the system are enough
to obtain good estimations for a given observable. In this work, Monte Carlo computer 
simulations were used for all the observables computed throughout.

\subsection{On the computation of the radial distribution function}
The procedure to obtain the radial distribution function from computer simulations is as
follows. For each Monte Carlo step a particle $i$ is chosen randomly.
Then, all the particles that are a distance $\delta r$ from the particle $i$ are counted
as a neighbor particle. After that, all the particles that are now at a distance
$2 \delta r$ from the particle $i$ are counted. This is done after all the particles
have been counted. If the interaction potential between the particles is truncated
to a cutoff radius $r_c$, then this is the last value of the distance used to count
neighboring particles. When every particle has been counted, a histogram is built,
which corresponds to a discrete distribution function of the neighboring particles. 
Now, this distribution function is not normalized, and the procedure to do so is as 
follows. A normalization constant is obtained by dividing the total number of particles at 
position $r$ with the product of the total number of particles in the simulation, 
multiplied by the total number of configurations visited throughout the simulation, 
multiplied by the total volume of the spherical shell that lies between $r$ and $r + \delta 
r$. In mathematical form, this can be summarized as follows
\begin{equation}
    g(r)=\frac{1}{\rho} \left\langle \frac{1}{N} \sum_{i=1}^{N} \sum_{i \neq j}^{N} 
    \delta (r - \vecr_{ij}) \right\rangle
    \, , \quad
    \vecr_{ij}=\vecr_{i} - \vecr_{j} \; ,
    \label{eq:rdf-simulation}
\end{equation}
where \(\left\langle \dots \right\rangle\) denotes an ensemble average.

\section{The Ornstein-Zernike Integral Equation} \label{sec:ornstein-zernike}
Up until this point, the presentation on Liquid State Theory has been driven by the
possibility of calculating a given observable for a liquid. The method to compute such
observables is to obtain a main quantity, the radial distribution function, and
make use of any of the thermodynamic equations that relate \rdf with the needed
thermodynamic observable. There has been a discussion of how the \rdf can be obtained
through computer simulations. And yet, there has not been a discussion of how the \rdf
can be obtained analytically. The Ornstein-Zernike formalism provides a way to obtain
such analytical results, and it is the focus of the present section, as well as the main 
focus of this thesis. Despite its importance, the formal derivation of the equation is too 
rigorous to be presented here, so most of the details will be omitted here but left to 
specific references on the subject~\cite{hansenTheorySimpleLiquids2013}. Nonetheless, the 
main results and physical interpretation shall be outlined here.

To understand the Ornstein-Zernike equation, a physical interpretation is defined as
follows. If there is a system of $N$ interacting particles with an interaction potential
defined by $u(r)$, then it so happens that each of them are related to each other.
It might seem like an obvious statement, but this relation has in fact two contributions.
There exists a \emph{direct} relation between particles and
their neighbors, and an \emph{indirect} relation between particles and the rest that
may be far away from them. This interaction begs the question,
\emph{is there a way to relate the indirect and direct correlations between particles?}
The answer is given recursively through the following definition. Let $h(r)$ be the
\emph{total correlation function} that "measures" the total correlations between
particles; and let $c(r)$ be the \emph{direct correlation function} that "measures"
the direct correlations between particles, then both $c(r)$ and $h(r)$ are related
with each other through the \emph{Ornstein-Zernike equation} as follows
\begin{equation}
    \begin{aligned}
        h(r) &= c(r) + \rho \int_{V} c(\vecr') \, c(\lvert \vecr - \vecr' \rvert) \, d \vecr' \\
        &+ \rho^2 \int_{V} c(\vecr'') c(\lvert \vecr - \vecr' \rvert) c(\lvert \vecr' - \vecr'' \rvert) \, d \vecr' \, d \vecr'' \\
        &+ \rho^3 \int_{V} c(\vecr''') c(\lvert \vecr - \vecr' \rvert) c(\lvert \vecr' - \vecr'' \rvert) c(\lvert \vecr'' - \vecr''' \rvert) \, d \vecr' \, d \vecr''
        \, d \vecr''' \\
        &+ \dots \; ,
    \end{aligned}
    \label{eq:hr-oz}
\end{equation}
with \(\rho \coloneqq N / V .\)
\autoref{eq:hr-oz} can be rewritten recursively by noting the following factorization
\begin{equation}
    h(r) = c(r) + \rho \int_{V} c(\vecr') \left[
    \begin{aligned}
        & \hspace{1.6cm} c(\lvert \vecr - \vecr' \rvert) \\
        &+ \rho \int_{V} c(\lvert \vecr - \vecr' \rvert) c(\lvert \vecr' - \vecr'' \rvert) \, d \vecr' \, d \vecr'' \\
        &+ \rho^2 \int_{V} c(\lvert \vecr - \vecr' \rvert) c(\lvert \vecr' - \vecr'' \rvert) c(\lvert \vecr'' - \vecr''' \rvert) \, d \vecr' \, d \vecr''
        \, d \vecr''' \\
        &+ \hspace{1.6cm} \dots
    \end{aligned}
    \right] \, d \vecr'
    \label{eq:oz-factorization}
\end{equation}
and thus arrive at the most common form of the Ornstein-Zernike equation, which for
isotropic and uniform liquids reads
\begin{equation}
    h(r) = c(r) + \rho \int_{V} c(r') \, h(\lvert \vecr - \vecr' \rvert) \, d \vecr'
    \, .
    \label{eq:ornstein-zernike}
\end{equation}

The Ornstein-Zernike integral equation provides an analytical way to obtain the \rdf 
provided an interaction potential. Yet, in \autoref{eq:ornstein-zernike} there is no 
mention or sign of any of such quantities. So how is it possible to obtain an estimate
of \rdf? It turns out that the definition of $h(r)$ is key to answering this question,
for the actual mathematical definition is $h(r) \coloneqq g(r) - 1$~\cite{hansenTheorySimpleLiquids2013}.
As for the interaction potential, the information lies within $c(r)$ and $g(r)$.
In the \emph{low density limit}, the radial distribution function has the following
asymptotic behavior
\begin{equation}
    g(r) \to e^{- \beta u(r)} \, , \quad \rho \to 0 \; .
    \label{eq:gr-asymp}
\end{equation}
Also, when $r \to \infty$ then $g(r) \to 1$. 
Now, again in the low density limit, the asymptotic behavior
for $c(r)$ that follows from \autoref{eq:ornstein-zernike} is that $c(r) \to h(r)$.
This also means that, with \autoref{eq:gr-asymp}, $c(r)$ has the following
limiting definition
\begin{equation}
    c(r) \to h(r) = g(r) - 1 = e^{- \beta u(r)} - 1 \, , \quad \rho \to 0
    \; ,
    \label{eq:cr-aysmp}
\end{equation}
where the function $f \coloneqq e^{- \beta u(r)} - 1$ is called the $f$-Mayer
function, and it is an important quantity for theoretical analysis in Liquid State
Theory. Thus, it follows from \autoref{eq:cr-aysmp} that
\begin{equation}
    c(r) = - \beta u(r) \, , \quad r \to \infty 
    \, .
    \label{eq:cr-r-asymp}
\end{equation}
An additional important fact is that the compressibility equation, \autoref{eq:chi-rdf},
can be defined in terms of the $c(r)$ functions as follows
\begin{equation}
    \frac{\beta}{\rho \chi_{T}} = 1 - \rho \int_{0}^{\infty} 4 \pi r^2 c(r) \, dr
    \, ,
    \label{eq:compressibility-cr}
\end{equation}
this definition follows from the relation between $c(r)$ and the
\emph{structure factor}~\cite{hansenTheorySimpleLiquids2013}, but the details are omitted 
here.

\subsection{Closure relations}
Now that it has been stated the relation between the three quantities, 
$c(r), \, g(r), \, \text{and} \, u(r)$, the solution to the Ornstein-Zernike equation
must be discussed. Until now, the discussion of the functions $c(r)$ and $h(r)$ has been
focused on their low density limit. Still, liquids are \emph{dense} systems and most of
the time the purpose of studying them is to understand their properties for a wide range
of density values, low and high density regimes. 
Furthermore, it is expected to study the phenomena that
arises when the density varies in ways that \emph{phase transitions} are induced.
To provide a solution to this, \autoref{eq:ornstein-zernike} must be solved for all possible
values of the density. However, if looked at closely, \autoref{eq:ornstein-zernike} has
two unknown functions, $c(r)$ and $h(r)$, thus cannot be solved as it is. For this reason,
approximations must be introduced in the form of \emph{closure relations}.

Closure relations come from diagrammatic expansions and density function theory~\cite{hansenTheorySimpleLiquids2013},
and are not simple to summarize in this section. The most common closure relations will be
stated, along those that are used in this work. One of the most important closure relations
is the \emph{Percus-Yevick} approximation.
The most important fact from this closure is that it provides an analytical solution to the 
hard sphere model. The closure relation reads~\cite{percusAnalysisClassicalStatistical1958},
\begin{equation}
    c(r) = g(r) \, \left[1 - e^{\beta u(r)}\right]
    \; ,
    \label{eq:py-cr}
\end{equation}
and when used along the hard sphere potential found in \autoref{eq:hard-sphere}, it provides
an exact solution for \rdf.
Another common closure relation is the \emph{Hypernetted Chain} approximation,
which reads~\cite{hansenTheorySimpleLiquids2013},
\begin{equation}
    c(r) = h(r) - \beta u(r) - \ln{g(r)} \; .
    \label{eq:hnc-cr}
\end{equation}
The appeal of this closure relation is that it works quite well for interaction potentials 
with long-range repulsive behavior, such as the Yukawa or Lennard-Jones potentials~\cite{hansenTheorySimpleLiquids2013}.
Despite this, both closure relations have deficiencies when attempting to predict a
phase transition. Moreover, these closure relations suffer from
\emph{thermodynamic inconsistency}. This is a phenomenon that happens from the approximation
nature of closure relations. Both closure relations give different results for
a given thermodynamic quantity if computed from different routes. For instance, if the 
thermodynamic pressure $P$ is computed using the Ornstein-Zernike and the 
Percus-Yevick closure relation, then, if \autoref{eq:pressure-equation} is used, a 
particular result will be obtained.
But if \autoref{eq:chi-rdf} is used, and then \autoref{eq:isothermal-chi} to obtain the 
thermodynamic pressure, a different result will be obtained with respect to the one
computed before. Furthermore, if the energy equation is used
\textemdash \autoref{eq:total-energy-rdf} \textemdash, 
and then using thermodynamic relations to obtain the pressure, a new result will be 
obtained, different from the previous two results. This constitutes a serious drawback of
the Ornstein-Zernike formalism.

To alleviate this main drawback, Rogers and Young~\cite{rogersNewThermodynamicallyConsistent1984b}
proposed a new version of the closure relation, which in fact combines two closure 
relations, the Hypernetted Chain and the Percus-Yevick. With great success, this new
and improved closure relation can reproduce the thermodynamics of the hard sphere model
and related short-range interaction potentials. Another attempt at providing thermodynamic
consistent closure relations were provided by Zerah and Hansen~\cite{zerahSelfConsistentIntegral1986},
which combined different closure relations into one, in the same fashion as the Rogers-Young
closure relation. Both of these approaches work as follows. Two main routes to compute a 
given thermodynamic quantity are chosen, and are forced to yield the same results through 
the use of a fixed parameter, called the \emph{mixing parameter}. This value is obtained as 
an optimization problem by enforcing equality of the thermodynamic routes.

Another important closure relation is the one provided by Verlet and then modified by
Kinoshita~\cite{kinoshitaInteractionSurfacesSolvophobicity2003}. It turns out that
when hard spheres are studied, there are better closure relations than the
Percus-Yevick approximations for larger density values.
The Kinoshita modification reads,
\begin{equation}
    B(r) = - 0.5 \frac{\gamma^2 (r)}{1 + 0.8 \lvert \gamma (r) \rvert} \; ,
    \label{eq:kinoshita}
\end{equation}
where $B(r)$ is the bridge function (see next section), and $\gamma(r)=h(r)-c(r)$,
and \(\lvert \cdot \rvert\) stands for the absolute value.
This closure relation is not thermodynamically consistent, but in this work this
consistency will be explored in detail.

\subsection{The role of the bridge function}
All the possible solutions to the Ornstein-Zernike equation discussed so far 
have been just approximations.
But the Ornstein-Zernike formalism is an exact integral equation, thus there should be an
exact closure relation. Indeed, an exact relation exists which comes from diagrammatic
expansions~\cite{hansenTheorySimpleLiquids2013} and reads,
\begin{equation}
    \ln{\left[h(r) - 1\right]} = \beta u(r) + B(r) + \gamma(r) \; .
    \label{eq:exact-closure}
\end{equation}
Still, it introduces a new function and quantity, the so-called \emph{bridge function}.
What role does the bridge function play in the exact solution of the Ornstein-Zernike
equation? It turns out that if chosen correctly, the bridge function can make
\autoref{eq:exact-closure} reduce to all previous closure relations. For instance,
if $B(r)=0$, the Hypernetted Chain closure relation is recovered. If now the bridge
function takes the value of $B(r)=\ln{ \{\gamma(r) + 1\} }-\gamma(r)$, then the 
Percus-Yevick approximation is obtained. Given the true nature of the bridge function,
physicists were drawn to understand the bridge function and proposed approximations for
the bridge function, instead of a simple closure relation for the Ornstein-Zernike
equation itself. Nevertheless, by approximating the bridge function, the same problems
arise, i.e., thermodynamic consistency and deficient results for every possible
interaction potential. So the most common way to solve the Ornstein-Zernike equation is through
experience: knowing the properties of $u(r)$, a given bridge function is chosen,
then with this approximation the Ornstein-Zernike equation is solved, and a solution is
obtained. Most of the time, the solution is extremely precise. But if there is not
much understanding of the interaction potential, then several bridge function approximations
must be tested. However, most of the important interaction potentials have been
extensively studied, and it is already known how these behave and their properties.
But it is still cumbersome to attempt to use all possible bridge function approximations.
It seems like a task that could be \emph{discovered} or \emph{automated} in a way, and
fortunately this is what Machine Learning excels at.