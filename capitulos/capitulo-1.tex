\chapter{Introduction}
\label{Cap1}

Since the mainstream adoption of \emph{Machine Learning} (ML) methods
on common tasks such as object recognition, computer vision,
and human-computer interactions~\cite{lecunDeepLearning2015},
scientists have tried to adopt most of these techniques to further research
in their respective fields. From drug development~\cite{redaMachineLearningApplications2020}
to genetics and biotechnology~\cite{libbrechtMachineLearningApplications2015},
multiple applications of ML to current research problems have seen
widespread interest for their generalization and automatic discovery attributes.
It is with the inspiration from these applications that physicists have attempted to use 
such methods in diverse Physics fields~\cite{carleoMachineLearningPhysical2019a,dunjkoMachineLearningArtificial2018,carrasquillaMachineLearningPhases2017a}.

Most of the attempts and successes of using ML methods in Physical sciences come from
the direct application of common ML pipelines and uses, such as \emph{classification},
\emph{regression}, and \emph{unsupervised learning}~\cite{hastieElementsStatisticalLearning2009}, just to name some.
Such is the case of the determination of the
critical point of the Ising model as means of a classification task~\cite{carrasquillaMachineLearningPhases2017a}.
Similar is the case of the use of \emph{computer vision} and \emph{deep learning} 
techniques in particle physics, which have seen great applications when dealing with 
experimental data~\cite{radovicMachineLearningEnergy2018}.
In each of the previous examples, scientists have taken the most common applications
of ML methods and have adjusted them for their respective research problems.
This has the advantage that such ML techniques have been extensively researched
and developed, so physicists know that these methods are robust and useful for
the problems they have been developed for.
However, it turns out that not all ML techniques can be readily applied to the problem
at hand, and physicists should instead try to capitalize on the Physics of the problem and
use it along with the ML method to boost its usefulness, flexibility and accuracy.

It is with this perspective that physicists have preferred to incorporate most of the 
Physics into the ML method, and thus create a new form of
\emph{physics-inspired machine learning}~\cite{karniadakisPhysicsinformedMachineLearning2021a}.
One such example is the Behler-Parrinello neural network approach for energy surfaces
in the Density Functional Theory framework~\cite{behlerGeneralizedNeuralNetworkRepresentation2007a}.
Within such proposal, Behler and Parrinello chose to use some functions whose 
definition and composition are based on the properties of the system studied, which were 
atoms and their components,
and use such information as input to a \emph{regression} scheme to approximate the
energy surface of the studied system. At the moment of publication, this approach
defined a new paradigm of ML application within the physical sciences. It was no longer
the fact that simple learning tasks were used, but by including physical descriptors
in the ML methods, new ways of obtaining the same results were found.
Not only do ML methods provide mostly the same results as the physical framework they
are modeling, they also provide solutions much faster and more efficiently~\cite{zhuPhysicsconstrainedDeepLearning2019}.

Of all the research fields within Physics, in this thesis we would like to focus
our attention to the field of \emph{condensed matter physics}, and in particular, to the
field of Liquid State Theory and Soft Matter. Before we do that, however, we should
mention briefly some of the precursors to the applications of ML to said fields.
A great review by J\"{o}rg Behler~\cite{behlerPerspectiveMachineLearning2016a}
describes in great detail some of these precursors. Most applications have dealt with
materials science, computational chemistry and chemistry, and the computational aspect
of condensed matter physics. It is within these fields that new ways of using ML methods
have been developed from various needs in research. Another prime example is the coupling
of computer simulations and ML methods, such as the work by Li \emph{et al}~\cite{liMolecularDynamicsOntheFly2015}.
In this work, whenever the quantum-mechanical information is needed it is computed with
first-principles calculations. These calculations are then added to a dataset to be used
by ML methods, which in turn are used as approximators for the computer simulation.
This approach not only efficiently uses Physics in its most pure form, but it also
adopts the ML best attributes and uses them to its advantage.
For a more complete overview of some of the most impactful applications, the
review by Bedolla \emph{et al}~\cite{bedollaMachineLearningCondensed2020}
covers these and some other important aspects of ML methods applied to
condensed matter physics.

Although these are a tiny subset of all the modified applications of ML techniques
in physical sciences research, we should note that these show an important aspect
in common between them. If we wish to assimilate the physics of the problem at hand,
variations and modifications to the common ML methods and techniques are needed. 
Exploration and testing, trial and error, are an important part of the search and 
application of ML methods to Physics research. In the case of Liquid State Theory and Soft 
Matter, we can consider that most research is still in the exploration and testing stage,
although some applications have seen great success in specific scenarios.
One such successful application is the use of \emph{Support Vector Machines}\textemdash
an explicit method useful for classication and regression based on kernels and
quadratic optimization~\cite{steinwartSupportVectorMachines2008}\textemdash
in the description of the properties of glassy dynamics~\cite{schoenholzStructuralApproachRelaxation2016}.
The reason for research in Soft Matter and ML still being part of the exploration step is 
that in Soft Matter and Liquid Theory it is hard to find suitable descriptors that 
actually tell useful information from the system or phenomena~\cite{dijkstraPredictiveModellingMachine2021a}.
As such, most of the time a descriptor-based approach might not be feasible for every 
possible system. Instead, we need to explore a diverse range of possibilities when using ML 
methods within the context of Soft Matter and Liquid Theory.

%% TODO: Continuar con el hilo de la exploración en materia blanda y teoría de líquidos. Mencionar algunos de los artículos de Boattini, Dijkstra, Truskett y otros sobre Materia Blanda. En un párrafo en particular hablar sobre el resultado de Goodall-Lee sobre la ecuación de OZ, y con esto comenzar la discusión de la tesis. Al final, mencionar cómo está distribuida la tesis, los capítulos y todo eso. (2 párrafos para los artículos, un párrafo para Goodall-Lee, y un párrafo para la distribución del texto)