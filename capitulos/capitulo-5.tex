\chapter{Evolutionary optimization for the Kinoshita closure}
\label{Cap5}

In the previous chapter, a neural network was used to approximate the bridge function in 
the solution to the Ornstein-Zernike (OZ) equation. From the results obtained, it was 
implied that, without any more physical information, the neural network reduced its 
approximation to the well-known Hypernetted Chain closure relation. In this chapter, the 
modified Verlet bridge function is introduced, along with its variation, the Kinoshita 
closure. This bridge function contains more information in terms of the indirect 
correlation function, \(\gamma(r)\), which provides a more accurate solution when dealing 
with the hard-sphere fluid. Still, the Kinoshita closure is not thermodynamically 
consistent. Thus, in this chapter, the proposal of parametrizing the Kinoshita is 
introduced. These parameters are then fitted using Evolutionary Computation (EC) method for 
derivative-free optimization tasks. This is in the same spirit as with the 
Rogers-Young~\cite{rogersNewThermodynamicallyConsistent1984b} and the 
Zerah-Hansen~\cite{zerahSelfConsistentIntegral1986} closure relations. The goal of this 
proposal is to alleviate the problems that using a neural network has, in terms of 
incoporating more Physics into the modeling, instead of relying on the neural network to 
learn something by its own.

\section{The Kinoshita closure and its parametrization}
The proposal in this chapter deals with the modified Verlet closure and a variation of 
this, the Kinoshita modification. Both of these closure relations have been formulated to 
deal with the hard-sphere fluid, for low and large density values. The purpose of this 
section is to look at these closure relations more closely, as well as to define the 
parametrization to be used in later computations and results.

\subsection{The modified Verlet bridge function approximation}
Between 1980 and 1981, Loup Verlet published two papers were he introduced what is now 
called the \emph{modified Verlet} bridge 
function~\cite{verletIntegralEquationsClassical1980,verletIntegralEquationsClassical1981}. 
The idea behind his bridge function approximation was to derive a good approximation based 
on reproducing the exact first five virial coefficients of the hard sphere equation of 
state. The original proposition for the bridge function by Verlet was,
\begin{equation}
    B(r) = - \frac{A \, \gamma^{2}(r) \, / 2}{1 + B \, \gamma(r) \, / 2}
    \; .
    \label{eq:verlet-params}
\end{equation}
By fitting the exact values of the virial coefficients, Verlet reached the conclusion that 
the values for \(A, B\) that could reproduce the results for the hard-sphere fluid up to 
the fluid-solid transition where the values of,
\begin{equation}
    A = 1 \, , \quad B = \frac{4}{5}
    \; ,
    \label{eq:ab-verlet}
\end{equation}
which turns the original closure relation in \autoref{eq:verlet-params} into,
\begin{equation}
    B(r) = - \frac{0.5 \, \gamma^{2}(r)}{1 + 0.8 \, \gamma(r)}
    \; .
    \label{eq:mVerlet}
\end{equation}
This turned out to be an accurate bridge function approximation for the case of the 
hard-sphere fluid, even when hard sphere mixtures are 
% considered~\cite{lopez-sanchezDemixingTransitionStructure2013a}.
Some of the advantages of this approximation is the fact that it is simple, efficient and 
there are no free parameters to be fixed, as is the case in the 
Rogers-Young~\cite{rogersNewThermodynamicallyConsistent1984b} and the 
Zerah-Hansen~\cite{zerahSelfConsistentIntegral1986} closure relations. The problem lies, as 
with other closure relations, with the fact that the bridge function in 
\autoref{eq:mVerlet} is not thermodynamically consistent. There are other closure relations 
which are already thermodynamically consistent, as is the case of the reference Hypernetted 
Chain approximation~\cite{ladoSolutionsReferencehypernettedchainEquation1983}. This 
approximation comes from first principles, and the thermodynamic consistency comes from the 
fact that the reference potential is chosen such that the free energy of the fluid is 
minimized. Still, the problem with this closure relation, although accurate, is that is 
might be hard to implement and use in several different scenarios.

\subsection{The Kinoshita variation}
For this reason, the idea of this chapter is to use the modified Verlet approximation, and instead of using the fixed parameters found from theoretical arguments, to let an evolutionary algorithm find the best ones that can also establish thermodynamic consistency. For this reason, the Kinoshita variation~\cite{kinoshitaInteractionSurfacesSolvophobicity2003} to the modified Verlet closure relation is introduced. This variation reads,
\begin{equation}
    B(r) = - \frac{0.5 \, \gamma^{2}(r)}{1 + 0.8 \, \left\lvert \gamma(r) \right\rvert}
    \; ,
    \label{eq:kinoshita-eq}
\end{equation}
and introduces the absolute value \(\left\lvert \cdot \right\rvert\) in the denominator, 
which increases the numerical stability of the closure relation for the case when there are 
very large and negative values of \(\gamma(r)\). However, in this case, the idea is to leave the original form of the closure relation, that is with two free paramaters,
\begin{equation}
    B(r) = \frac{\alpha \, \gamma^{2}(r)}{1 + \beta \, \left\lvert \gamma(r) \right\rvert}
    \; ,
    \label{eq:kinoshita-params}
\end{equation}
and instead look for the best values of both \(\alpha, \beta\) that yield an accurate 
result for the case of the isotropic hard sphere fluid in three dimensions.
To find these values, partial thermodynamic consistency will be enforced through the use of 
the pressure equations, which shall be discussed next.

\section{Thermodynamic consistency}
An important part of the results from this chapter is the notion of 
\emph{thermodynamic consistency}, the way it works and how it is implemented numerically. 
This is the goal of the present section.

When approximations to the bridge function are used, together with the OZ equation, most of 
the time the solution show a phenomenon where, if a thermodynamic observable is computed 
through two or more \emph{routes}, the results may vary drastically. This is not wanted 
behavior from the closure relations. Rather, it is expected that the closure relations 
could, in fact, provide accurate results regardless of the route they are computed with.
In section \autoref{sec:thermodynamics}, some of the ways to compute thermodynamic 
quantities using the radial distribution function, \(g(r)\), were presented. These will be 
presented here once more for the sake of clarity. Specialy, it is important to mention the 
two main routes that will be used later, the \emph{virial route} and the 
\emph{compressibility route}.

From \autoref{eq:pressure-equation}, the pressure equation for a $3$-dimensional fluid is,
\begin{equation}
    P = \frac{\rho}{\beta} - \frac{2 \pi \beta \rho}{3} \int_{0}^{\infty} u'(r) \, g(r) \, r^3 \, dr \, ,
    \label{eq:pressure-gr}
\end{equation}
this equation is also known as the \emph{virial equation} because it can be derived 
formally with the virial theorem (see \autoref{sec:thermodynamics}). Henceforth, 
this equation shall be known as the \emph{virial pressure equation}.

Another quantity of interest is the \emph{isothermal compressibility}, which was already 
introduced in \autoref{sec:thermodynamics}, and can be computed using the \(c(r)\) function 
as follows~\cite{hansenTheorySimpleLiquids2013},
\begin{equation}
    \frac{\beta}{\left( \chi_{T} \,  \rho \right)} = 1 - \rho \int d \vecr \, c(r)
    \; .
    \label{eq:compress-gr}
\end{equation}
For this reason, this equation shall be known throughout the rest of this thesis as the 
\emph{compressibility equation}. Using Thermodynamics, one can relate the pressure \(P\) of the system to the isothermal compressibility using the expression,
\begin{equation}
    \chi_{T} = - \, \frac{1}{V} { \left( \frac{\partial V}{\partial P} \right) }_{T} =
    \frac{1}{\rho} { \left( \frac{\partial \rho}{\partial P} \right) }_{T}
    \; ,
    \label{eq:chi-thermo}
\end{equation}
which is the same as in \autoref{eq:isothermal-chi}, again from 
\autoref{sec:thermodynamics}.

By enforcing that the pressure computed from \autoref{eq:pressure-gr} and the pressure 
computed from \autoref{eq:compress-gr} and then using \autoref{eq:chi-thermo}, are equal to 
some arbitrary precision, closure relations can be \emph{thermodynamically consistent}. 
This would mean that both routes will yield the same value. In reality, not many closure 
relations can do this, except for some special cases, which were already mentioned in the 
previous section. Thus, the standard way of alleviating the problem of thermodynamic 
inconsistency is to compute both these routes and adjust some parameter, or function, 
such that both routes provide the same result. It need not be just the pressure equations, 
also the energy equations can be used, as well as other thermodynamic quantities, such as 
the Helmholtz free energy or the chemical 
potential~\cite{tsedneeClosureOrnsteinZernikeEquation2019}.

\subsection{Numerical implementation}
In order to be able to compute the pressure from both routes, the \emph{virial} route and the \emph{compressibility} route, the following approach was followed.

For the case of the \emph{virial} route, \autoref{eq:pressure-gr} was computed as is, using 
the Romberg method for computing the integral~\cite{hammingNumericalMethodsScientists2012}. 
Due to the fact that the interaction potential is a continuous function (see 
\autoref{eq:cont-hs}), the exact derivative was computed and implemented. Then, to compute 
the isothermal compressibility from \autoref{eq:chi-thermo}, the derivative was 
approximated using a finite central difference scheme,
\begin{equation}
    \chi_{T}^{-1} = \rho { \left( \frac{\partial P}{\partial \rho} \right) }_{T}
    \approx \rho \lim_{\Delta \rho \to 0} \frac{P(\rho + \Delta \rho) - P(\rho - \Delta \rho)}{2 \, \Delta \rho}
    \; ,
    \label{eq:central-difference}
\end{equation}
where \(\chi_{T}^{-1}\) is the inverse isothermal compressibility. The notation 
\(P(\rho + \Delta \rho)\) means that, for a particular value of density given by 
\(\rho^{\prime}=\rho + \Delta \rho\), as well as for a fixed temperature \(T\), 
\autoref{eq:pressure-gr} was used to compute the 
pressure through the virial route. Here, \(\Delta \rho\) is a small value, fixed to be
\(\Delta \rho=\num{1e-10}\) in the results presented in this chapter. Other central 
differences were explored, such as the five stencil 
approximation~\cite{hammingNumericalMethodsScientists2012}, however, the results obtained 
were as accurate as those obtained with \autoref{eq:central-difference}, so there was no 
reason to justify the extra computational resources needed to do a five stencil difference 
scheme.

For the case of the \emph{compressibility} route, \autoref{eq:compress-gr} was computed as 
is, using once again the Romberg method for computing the integral.

\section{Black-box optimization problem implementation}
\begin{figure}
    \centering
    \vspace{-2cm}
    \includegraphics[scale=0.3]{figuras/capitulo-5/black-box-function.png}
    \vspace{-3cm}
    \caption{Schematics of the black-box function implementation. The function takes in two parameters, \(\alpha, \beta\), and yield the output given by the squared difference of the inverse isothermal compressibility through the virial and compressibility routes.}
    \label{fig:black-box-function}
\end{figure}

In order to solve the problem of finding the best set of values \(\alpha, \beta\) in 
\autoref{eq:kinoshita-params} that would provide thermodynamic consistency, a special type 
of setup must be implemented. It must be recalled that the main objective is for the virial 
and compressibility routes to provide the same value, thus, an \emph{optimization problem} 
can be setup. The problem can be formulated as an \emph{unconstrained optimization} problem,
\begin{equation}
    \underset{\alpha \, , \beta}{\text{minimize}} \: {\left[
        {\left(\chi_{T}^{c} \left(\alpha, \beta\right) \right)}^{-1} - {\left(\chi_{T}^{v} \left(\alpha, \beta\right) \right)}^{-1} \right]}^2
    \; ,
    \label{eq:optimiziation-chi}
\end{equation}
where \({\left(\chi_{T}^{c}\right)}^{-1}\) is the inverse isothermal compressibility 
computed through the \emph{compressibility} route; \({\left(\chi_{T}^{v}\right)}^{-1}\) is 
the inverse isothermal compressibility computed through the \emph{virial} route; and the 
notation \({\left(\chi_{T}^{c, v} \left(\alpha, \beta\right) \right)}^{-1}\) represents the 
dependency of the parameters \(\alpha, \beta\) that would yield such value of the 
compressibility. In other words, for a fixed set of paramaters \(\alpha, \beta\), the 
inverse isothermal compressibility is computed via both routes, and its difference squared 
is computed. The goal of the optimization problem is to \emph{minimize} this difference. If 
a good set of parameters is found, the the difference will be, ideally, zero or close to 
zero, which in turn would mean that both routes are providing the same results, up to an 
arbitrary numerical tolerance.

In order to perform the optimization procedure, all the necessary computation must be bundled together into a single \emph{black-box function}. This function, which is modeled in \autoref{fig:black-box-function}, will take as input two values and will output the difference between the inverse isothermal compressibility values computed using both routes. Thus, the function will perform the following steps:
\begin{enumerate}
    \item Take as input two fixed values, \(\alpha^{\prime}, \beta^{\prime}\), and use them to define the Kinoshita closure in \autoref{eq:kinoshita-params}.
    \item Solve the OZ equation (see \autoref{AppendixB}) with the closure relation provided in the previous step. This will output two important quantities, the radial distribution function, \(g(r)\), and the direct correlation function, \(c(r)\).
    \item Using \autoref{eq:pressure-gr} and the details presented in the previous section, \({\left(\chi_{T}^{v}\right)}^{-1}\) is computed.
    \item Then, using \autoref{eq:compress-gr} and the details presented in the previous section, \({\left(\chi_{T}^{c}\right)}^{-1}\) is computed.
    \item After both routes have been computed, its squared difference is computed, i.e., \({\left[ {\left(\chi_{T}^{c} \left(\alpha, \beta\right) \right)}^{-1} - {\left(\chi_{T}^{v} \left(\alpha, \beta\right) \right)}^{-1} \right]}^2 \).
\end{enumerate}
Thus, the previous steps comprise the \emph{black-box function} shown in 
\autoref{fig:black-box-function}, which will later be minimized.

\subsection{Optimization procedure}
To solve the optimization problem in \autoref{eq:optimiziation-chi}, Evolutionary 
Comptuation methods were employed. However, there are two parts to the solution of this 
problem. First off, the function is treated as a \emph{black-box function}, which means 
that no derivatives can be computed, and that it is assumed that each function evaluation 
is costly. Although the numerical methods are quite optimized, it is safe to assume that 
each function evaluation is costly, and use this argument to select a good optimization 
method that can effectively reduce the number of function evaluations.

For this reason, Evolution Strategy methods were employed, in particular, Natural Evolution 
Strategies (NES) (see \autoref{Cap3}). These methods are robust, albeit slow to reach a 
minimum. 
Furthermore, these methods are \emph{global optimization methods}, meaning that these 
method will only look for global values throughout the function lanspace, and if any minima 
is found, it will not look deeper into that particular set of parameters. For this reason,
\emph{local optimization methods} are used, to perform a more exhaustive search into the 
previously found global minima. Thus, the optimization procedure looks like the following,
\begin{enumerate}
    \item Select an initial search space of \(\left[-75, 75\right]\) for each parameter, and choose an initial set of parameters randomly from within the search space.
    \item Using the DXNES global optimization method~\cite{nomuraDistanceweightedExponentialNatural2021}, perform a search for all the global minima in the interval \(\rm{x} \in \left[a, b\right]\).
    \item Keep the minima that satisfy the condition \(\rm{x} \leq 0.5\).
    \item Using a local optimization method, the BOBYQA method~\cite{powellUOBYQAUnconstrainedOptimization2002}, take as input the parameters found by the previous two steps, \(\rm{x}^{\prime}\). Use these within a shorter interval of \(\pm 5\) for each parameter, and look for a new set of parameters.
    \item Stop the optimization procedure when the new set of parameters satisfy the condition \(\rm{x}^{*} \leq \num{1e-7}\).
\end{enumerate}

To see this more clearly, an example is worked out now. First, a density value is fixed, 
\(\phi = 0.4\), and all the necessary parameters to solve the OZ equation are fixed as 
well. Then, the search is space is fixed to be \(\rm{x} = \left(\alpha, \beta\right) \in \left[-75, 75\right]\). 
An initial set of parameters is chosen randomly from within this search space, for 
instance, \(\rm{x} = \left(-10, 42\right)\). These pair of values are then fixed to be the 
value of \(\alpha, \beta\) in \autoref{eq:kinoshita-params}. With these new values, the 
closure relation is fixed and the OZ equation is solved. If the OZ equation can be solved 
using these values, then the result of the OZ equation is the pair of functions 
\(g(r), c(r)\). Using these values, and the details from the previous section, the squared 
difference 
\[
    \Delta \chi^{-1}_{T} = {\left[ {\left(\chi_{T}^{c} \left(\alpha, \beta\right) \right)}^{-1} - {\left(\chi_{T}^{v} \left(\alpha, \beta\right) \right)}^{-1} \right]}^2 
\; ,
\] 
is computed, and the global optimization method registers this value. If the value 
\(\Delta \chi^{-1}_{T}\) satisfies the condition \(\Delta \chi^{-1}_{T} \leq 0.5\), then 
the set of values \(\rm{x} = \left(-10, 42\right)\) is used for the local optimization 
method. However, in this case, the search space is bounded about these values by a factor 
of \(5\). In this example, that would mean that the new search space for the local 
optimization method would be \(\alpha \in [-15, -5]\) for the first parameter, and 
\(\beta \in [37, 47]\) for the second parameter. Then, the local optimization method would 
start looking for the minimum in this search space, and when a set of values satisfy the 
condition \(\rm{x}^{*} \leq \num{1e-8}\), then the optimization procedure has converged, 
and the set of values are regarded as the best values that provide thermodynamic 
consistency.

\section{Results}
In this section, the results obtained are presented; these results are also summarized in \autoref{tab:global-opt} and \autoref{tab:local-opt}. The results obtained are the two parameters computed through the optimization procedure described in the previous section, as well as the values of the isothermal compressibility computed using both routes.

\subsection{Kinoshita paramaters}
\begin{table}
    \centering
    \begin{tabular}{|c|c|c|}
    \hline
    \(\eta\)  & Parameters \(\left(\alpha, \beta\right)\)  & Fitness (minimum)    \\ \hline
    0.10 & {[}5.05, 7.89{]}    & 0.11          \\ \hline
    0.15 & {[}-1.74, 17.87{]}   & 0.02          \\ \hline
    0.20 & {[}-1.15, 5.16{]}    & 0.02   \\ \hline
    0.25 & {[}-6.43, 39.74{]}   & 0.45  \\ \hline
    0.30 & {[}-12.65, 39.23{]} & 0.1  \\ \hline
    0.35 & {[}-16.91, 47.15{]}    & 0.21  \\ \hline
    0.40 & {[}-27.44, 74.81{]}  & 0.08  \\ \hline
    0.45 & {[}-28.99, 71.32{]}  & 0.03 \\ \hline
    \end{tabular}%
    \caption{Results obtained directly from the optimization procedure for different values of volume fractions, \(\eta\). Here, the fitness or minimum represents the best value of \(\Delta \chi^{-1}_{T}\) that satisfies the condition \(\Delta \chi^{-1}_{T} \leq 0.5\).}
    \label{tab:global-opt}
\end{table}

\begin{table}
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \(\eta\)  & Parameters \(\left(\alpha, \beta\right)\) & \(\beta \, {\left(\chi^{v}_{T} \, \rho\right)}^{-1}\) (Virial)  & \(\beta \, {\left(\chi^{c}_{T} \, \rho\right)}^{-1}\) (Compressibility)  \\ \hline
    0.10 & [-1.39, 9.82]   & 2.19777  & 2.19778 \\ \hline
    0.15 & [-3.11, 17.87]  & 3.26186 & 3.26187  \\ \hline
    0.20 & [-1.35, 5.09]   & 4.79978  & 4.79972  \\ \hline
    0.25 & [-10.52, 41.28] & 7.28143  & 7.28142 \\ \hline
    0.30 & [-12.64, 42.16] & 10.96744 & 10.96747 \\ \hline
    0.35 & [-16.78, 49.43] & 16.64003 & 16.64005 \\ \hline
    0.40 & [-27.87, 74.52] & 25.4941 & 25.4943 \\ \hline
    0.45 & [-28.81, 71.35] & 39.0225  & 39.0226  \\ \hline
    \end{tabular}
    \caption{Results obtained from the local optimization procedure. The last two columns represent the inverse isothermal compressibility, from the virial and compressibility routes respectively.}
    \label{tab:local-opt}
\end{table}

For the parameters \(\alpha, \beta\), the optimization procedure of the previous section 
was followed, first using a global optimizer, and then a local optimizer, until the 
precision for the minimum was at least \(\leq \num{1e-8} .\) 
In \autoref{tab:global-opt}, the values for the global optimization procedure are shown. 
There, the minimum is at least less or equal than \(0.5\). 
Up to this point, the results betwen the virial and compressibility routes were not distant 
from each other, numerically speaking. However, when the parameters found were used to 
search for more accurate minima, the results were promising. This can be seen in 
\autoref{tab:local-opt}, where the results using the local optimizer are shown. It is now 
clear that both routes give the same results, which shows that the Kinoshita closure is now 
thermodynamically consistent, at least partially through the pressure equations.

\subsection{Isothermal compressibility of the hard sphere fluid}
\begin{figure}
    \centering
    \includegraphics[scale=0.32]{figuras/capitulo-5/chi-eta.pdf}
    \caption{Isothermal compressibility of the hard sphere fluid for different density values, expressed in terms of the volume fraction, \(\eta .\) The solid line is the isothermal compressibility obtained from the Kolafa equation of state (Kolafa EOS)~\cite{kolafaAccurateEquationState2004}. The squares are obtained from the optimization procedure, reported in \autoref{tab:local-opt}.}
    \label{fig:isothermal-results}
\end{figure}

To showcase the results obtained, a direct comparison of the isothermal compressibility 
values are plotted against the Kolafa equation of state (Kolafa EOS) in 
\autoref{fig:isothermal-results}. To obtain this plot, the isothermal compressibility was 
computed in its reduced form,
\begin{equation}
    \chi_{T}^{*} =  \frac{\chi_{T}}{\beta \, \sigma^3}
    \; ,
    \label{eq:reduced-chi}
\end{equation}
and also the results from \autoref{tab:local-opt} were multiplied by the reduced particle 
number density, \(\rho^{*} = \rho / \sigma^3 .\)

In the case of the Kolafa EOS, the equation reads,
\begin{equation}
    Z = \frac{P V \beta}{\rho} = \frac{1 + \eta + \eta^2 - \frac{2}{3} (\eta^3 + \eta^4)}{{\left(1 - \eta\right)}^{3}}
    \label{eq:kolafa}
\end{equation}
with \(\eta = \frac{\pi}{6} \rho^{*} .\) This is an important fact about hard sphere 
fluids; in general their equation of state can always be represented in terms of the 
geometry of the system, i.e., its volume fraction.
Then, to compute the isothermal compressibility, the equation of state needs to be 
differentiated, and the expression is~\cite{liuCarnahanStarlingTypeEquations2021},
\begin{equation}
    \chi_{T}^{*} = {\left[\left(\eta \, \frac{\partial Z}{\partial \eta} + Z\right) \cdot \rho^{*}\right]}^{-1}
    \; .
    \label{eq:chi-eos}
\end{equation}
Using \autoref{eq:chi-eos}, the solid line in \autoref{fig:isothermal-results} was 
computed, along with the results from \autoref{tab:local-opt}. It is simple to see that the 
results are in excellent agreement with the results obtained from the Kolafa EOS, which is 
considered to be a very accurate equation of state for the hard sphere fluid.

\section{Discussion}
It seems that, with the results shown in \autoref{fig:isothermal-results}, this approach is 
a great proposal for alleviating the thermodynamic consistency problem that permeates the 
bridge function literature. Indeed, the results show a lot of promise for the
\emph{optimization procedure} itself, but there are some important aspects that need to be 
pointed out.

\subsection{Thermodynamic consistency as an optimization problem}
The proposal of this chapter is to extend the Kinoshita closure in 
\autoref{eq:kinoshita-params}, and find the best values for the closure that can provide 
partial thermodynamic consistency. However, this proposal is not a new one, and in fact, 
Verlet himself established a proposal quite similar using his own bridge function 
approximation~\cite{verletIntegralEquationsClassical1981}. Still, in his proposal there 
are \emph{three free parameters} to adjust, and the optimization procedure is quite 
different. Rogers-Young~\cite{rogersNewThermodynamicallyConsistent1984b} and 
Zerah-Hansen~\cite{zerahSelfConsistentIntegral1986} are two of the fundamental proposals 
using the same idea, with just one free parameter two adjust, and interpolating between two 
well-established bridge functions. Further, the recent contribution by Tsednee and 
Luchko~\cite{tsedneeClosureOrnsteinZernikeEquation2019} of fixing the parameters of a 
series expansion was also posed as an optimization problem. However, in their work, there 
is no clear expression of how or why the optimization problem is handled, and just a hint 
of the local optimizer used is mentioned, which was the \verb|fmin| function in the 
MATLAB programming language.

In this thesis, the idea is simply to free up the fixed parameters in the Kinoshita bridge 
function approximation, which has shown the potential to be extended to mixtures of hard 
sphere fluids and other more complex systems. Further, the idea of an optimization 
problem based on black-box modeling seems to be a great way of thinking about the problem 
itself, given that the consistency enforced here is just partial, there are a lot more 
thermodynamic quantities that \emph{should} be adjusted as well, such as the chemical 
potential or the free energy. This is because more advanced techniques can be used, such as 
surrogate-base optimization~\cite{forresterRecentAdvancesSurrogatebased2009}, which 
attempts to build a surrogate, or substitute, model of the original black-box function, 
which can now be differentiable and more easily optimized. But this leads to another 
important point of discussion.

\subsection{The search space and the solution of the Ornstein-Zernike equation}
Although the results seem promising, one of the drawbacks encountered in this chapter when 
computing the results was the \emph{definition of the search space}, and the solution of 
the OZ equation in such a search space. Evolutionary Computation 
methods are \emph{population-based}, meaning that these methods generate a fixed set of 
possible solutions, and all solutions are tested and tried out by the optimization method. 
Though, it turns out that the OZ equation is \emph{not solvable} for a lot of parameters 
\(\alpha, \beta\) that are searched and sampled by the optimization method. In fact, at 
least 40\% of the parameters searched that were tried as possible solutions for the 
optimization problem in \autoref{eq:optimiziation-chi}, rendered the numerical solution of 
the OZ equation impossible. The data for this argument is not shown here, because there is 
not much to show regarding numerical errors and numerical instabilities.

This finding is quite important, because it shows that the OZ equation is only solvable for 
certain value of the parameters \(\alpha, \beta\), but no clear pattern is shown or easy to 
see. The only clue to this phenomenon is that the actual problem, which are just numerical 
instabilities of the numerical scheme. This would mean that, as in the previous chapter, a 
different numerical scheme could be used, maybe based of Krylov sub-space methods, 
following the original proposal by Gilles Zerah~\cite{zerahEfficientNewtonMethod1985}. Or 
it could also mean that there are several values and search subspaces for which the 
parameters \(\alpha, \beta\) do not provide a good bridge function approximation. But it is 
not clear \emph{how} or \emph{why} the bridge function approximation would not provide at 
least a solution to the OZ equation.

The search space is another important part of the problem. A large search space means that 
the optimization procedure must look into very different places until a particular minima 
has been found. This could be solved by restricting the bounds to particular bounds in both 
\(\alpha, \beta\), instead of using a single large search space for both paramaters. 
However, this is not simple to see, or to define. One way to do this would be rely on the 
same argument used by Verlet~\cite{verletIntegralEquationsClassical1980}, and inform the 
optimization procedure of the virial coefficients for the hard sphere fluid.

\subsection{On the use of Natural Evolution Strategies}
Another drawback of the proposed method is the fact that Evolutionary Computation methods 
are slow. This has already been said in previous sections, but in this case this is 
important to mention briefly. Natural Evolution Strategies have to sample distribution 
probabilities, and this is costly. Not to mention that the actual black-box function might 
be costly as well. The method itself should just find some minima in a small period of 
time, but in this case, a large portion of the time was spent with failed solutions of the 
OZ equation. Indeed, several restarts of the numerical method were 
needed in order to find values whithin the search space, and most of the time, numerical 
instabilities were encountered. These methods are good enough for simple problems, such as 
smooth and analytical high-dimensional functions, but other methods might be able to solve 
the problem more quickly and efficiently, such as Differential 
Evolution~\cite{dasDifferentialEvolutionSurvey2011} methods, also part of the 
Evolutionary Computation family of methods.

However, a strong metric to compare different methods in this will be needed, specially 
when dealing with the Physics of the problem. This is because it might be possible that not 
\emph{all} the minima found will have Physical meaning, or it might just be that there are 
some local minima for which the bridge function yields accurate results. However, these 
methods will not discriminate between either of those, so a metric that could drive the 
optimization problem to Physical meaning would be a novel way to solve the problem of 
bridge function approximations.

\section{Concluding remarks}
The results shown here are clearly better than those shown in the previous chapter. Indeed, 
incorporating more information about the Physics of the system provides more robustness to 
the Computational Intelligence method. There needs to be a reformulation as well, but in 
general it is safe to say that this method is better in terms of accuracy, as is shown in
\autoref{fig:isothermal-results}, which would not be the case if the radial distribution 
functions were not estimated correctly.
In a sense, it is expected to see these results, because it is known that the Verlet bridge 
function, as well as the Kinoshita variation, are good functions for the hard sphere fluid.
What might not be too obvious, and a novel way of seeing the problem, is the fact that the
Kinoshita closure relation can be, in fact, thermodynamically consistent.

However, the results shown here are just a minimal working example of what can be done. 
An important aspect to study is the fact that the Neural Network approach of the previous 
chapter could be \emph{informed}, or combined, with the Kinoshita bridge function 
approximation, and instead of reducing to the Hypernetted Chain, it could potentially 
reduce to the Kinoshita closure relation. And yet, this seems like more work to do, because 
the Kinoshita closure only has two free paramaters, compared to the thousands of parameters 
that appear in a Neural Network. Still, the Neural Network is faster to fit and solve than 
using Evolutionary Computation methods, which could be extended to other systems as well.

The results here show great promise to be extended to other dimensions and systems. 
For instance, in highly asymmetric mixtures~\cite{zhouLocalStructureThermodynamics2019}, 
where several parameters could be found. The method shown here would not change at all, due 
to the fact that Evolutionary Computation methods naturally handle high-dimensional 
optimization problems. The only thing that would need to change is the solution to the OZ 
equation. Another aspect that could be explored is the study of hard disks and their 
mixtures, which is the generalization of the hard sphere fluid to a \(2\)-dimensional 
space. It would be interesting to see if the method itself holds, or if there are a lot 
more numerical instabilities that might show when different dimensions are handled.
An extension to other interaction potentials might be possible with this method as well. 
The study of the Lennard-Jones fluid, the Yukawa fluid, and many others, could be studied 
using this method, just to showcase the true robustness of the method.

Finally, another line of future research could be the comparison of different optimization 
algorithms for this kind of problems. A robust implementation that could be translated into 
a highly efficient code package could serve well the community of Liquid Theory and Soft 
Matter in general. Different optimization methods could yield better or worse results, or 
it could shed some light into what might be happening to the search space itself.