
@article{antaFastMethodSolving1995,
  title = {A Fast Method of Solving the Hypernetted-Chain Equation for Molecular {{Lennard}}-{{Jones}} Fluids},
  author = {Anta, J. A. and Lomba, E. and Mart{\'i}n, C. and Lombardero, M. and Lado, F.},
  year = {1995},
  month = mar,
  volume = {84},
  pages = {743--755},
  publisher = {{Taylor \& Francis}},
  issn = {0026-8976},
  doi = {10.1080/00268979500100511},
  abstract = {A fast and stable procedure for solving hypernetted-chain type integral equations for molecular Lennard-Jones fluids is presented. The method is a hybrid algorithm based on the combination of multidimensional angular integration of the closure relation and a linearization technique devised by Fries and Patey (1985, Molec. Phys., 55, 751). The combination of the two techniques leads to a remarkable reduction in the CPU time required to evaluate the closure relation in these systems, which is usually the most time-consuming task. As an application of the method, phase coexistence curves have been calculated for two-centre Lennard-Jones fluids with and without point dipoles.},
  annotation = {\_eprint: https://doi.org/10.1080/00268979500100511},
  journal = {Molecular Physics},
  number = {4}
}

@article{asadyUtilizingArtificialNeural2014,
  title = {Utilizing Artificial Neural Network Approach for Solving Two-Dimensional Integral Equations},
  author = {Asady, B. and Hakimzadegan, F. and Nazarlue, R.},
  year = {2014},
  month = apr,
  volume = {8},
  pages = {117},
  issn = {2251-7456},
  doi = {10.1007/s40096-014-0117-6},
  abstract = {This paper surveys the artificial neural networks approach. Researchers believe that these networks have the wide range of applicability, they can treat complicated problems as well. The work described here discusses an efficient computational method that can treat complicated problems. The paper intends to introduce an efficient computational method which can be applied to approximate solution of the linear two-dimensional Fredholm integral equation of the second kind. For this aim, a perceptron model based on artificial neural networks is introduced. At first, the unknown bivariate function is replaced by a multilayer perceptron neural net and also a cost function to be minimized is defined. Then a famous learning technique, namely, the steepest descent method, is employed to adjust the parameters (the weights and biases) to optimize their behavior. The article also examines application of the method which turns to be so accurate and efficient. It concludes with a survey of an example in order to investigate the accuracy of the proposed method.},
  journal = {Mathematical Sciences},
  language = {en},
  number = {1}
}

@article{baezUsingSecondVirial2018,
  title = {Using the Second Virial Coefficient as Physical Criterion to Map the Hard-Sphere Potential onto a Continuous Potential},
  author = {B{\'a}ez, C{\'e}sar Alejandro and {Torres-Carbajal}, Alexis and {Casta{\~n}eda-Priego}, Ram{\'o}n and {Villada-Balbuena}, Alejandro and {M{\'e}ndez-Alcaraz}, Jos{\'e} Miguel and {Herrera-Velarde}, Salvador},
  year = {2018},
  month = oct,
  volume = {149},
  pages = {164907},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/1.5049568},
  journal = {The Journal of Chemical Physics},
  number = {16}
}

@article{beardmoreNumericalBifurcationAnalysis2007,
  title = {A {{Numerical Bifurcation Analysis}} of the {{Ornstein}}\textendash{{Zernike Equation}} with {{Hypernetted Chain Closure}}},
  author = {Beardmore, R. E. and Peplow, A. T. and Bresme, F.},
  year = {2007},
  month = jan,
  volume = {29},
  pages = {2442--2463},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/060650659},
  abstract = {We study the codimension-one and -two bifurcations of the Ornstein\textendash Zernike equation with hypernetted chain (HNC) closure with Lennard\textendash Jones intermolecular interaction potential. The main purpose of the paper is to present the results of a numerical study undertaken using a suite of algorithms implemented in MATLAB and based on pseudo arc-length continuation for the codimension-one case and a Newton-GMRES method for the codimension-two case. Through careful consideration of the results of our computations, an argument is formulated which shows that spinodal isothermal solution branches arising in this model cannot be reproduced numerically. Furthermore, we show that the existence of an upper bound on the density that can be realized on a vapor isothermal solution branch, which must be present at a spinodal, causes the existence of at least one fold bifurcation along that vapor branch when density is used as the bifurcation parameter. This provides an explanation for previous inconclusive attempts to compute solutions using Newton\textendash Picard methods that are popular in the physical chemistry literature.},
  journal = {SIAM Journal on Scientific Computing},
  number = {6}
}

@article{bomontRenormalizationIndirectCorrelation2001,
  title = {Renormalization of the Indirect Correlation Function to Extract the Bridge Function of Simple Fluids},
  author = {Bomont, J. M. and Bretonnet, J. L.},
  year = {2001},
  month = feb,
  volume = {114},
  pages = {4141--4148},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/1.1344610},
  journal = {The Journal of Chemical Physics},
  number = {9}
}

@article{boothEfficientSolutionLiquid1999,
  title = {Efficient Solution of Liquid State Integral Equations Using the {{Newton}}-{{GMRES}} Algorithm},
  author = {Booth, Michael J. and Schlijper, A. G. and Scales, L. E. and Haymet, A. D. J.},
  year = {1999},
  month = jun,
  volume = {119},
  pages = {122--134},
  issn = {0010-4655},
  doi = {10.1016/S0010-4655(99)00186-1},
  abstract = {We present examples of the accurate, robust and efficient solution of Ornstein-Zernike type integral equations which describe the structure of both homogeneous and inhomogeneous fluids. In this work we use the Newton-GMRES algorithm as implemented in the public-domain nonlinear Krylov solvers NKSOL [P. Brown, Y. Saad, SIAM J. Sci. Stat. Comput. 11 (1990) 450] and NITSOL [M. Pernice, H.F. Walker, SIAM J. Sci. Comput. 19 (1998) 302]. We compare and contrast this method with more traditional approaches in the literature, using Picard iteration (successive-substitution) and hybrid Newton-Raphson and Picard methods, and a recent vector extrapolation method [H.H.H. Homeier, S. Rast, H. Krienke, Comput. Phys. Commun. 92 (1995) 188]. We find that both the performance and ease of implementation of these nonlinear solvers recommend them for the solution of this class of problem.},
  journal = {Computer Physics Communications},
  keywords = {GMRES,Inhomogeneous fluids,Krylov,Newton,Nonlinear integral equation,Numerical solution,Ornstein,Raphson,Zernike},
  language = {en},
  number = {2}
}

@article{carvalhoIndirectSolutionOrnsteinZernike2020,
  title = {Indirect {{Solution}} of {{Ornstein}}-{{Zernike Equation Using}} the {{Hopfield Neural Network Method}}},
  author = {Carvalho, F. S. and Braga, J. P.},
  year = {2020},
  month = oct,
  volume = {50},
  pages = {489--494},
  issn = {1678-4448},
  doi = {10.1007/s13538-020-00769-4},
  abstract = {Microscopic information, such as the pair distribution and direct correlation functions, can be obtained from experimental data. From these correlation functions, thermodynamical quantities and the potential interaction function can be recovered. Derivations of Ornstein-Zernike equation and Hopfield Neural Network method are given first, as a theoretical background to follow the present work. From these two frameworks, structural information, such as the radial distribution (g(r)) and direct correlation (C(r)) functions, were retrieved from neutron scattering experimental data. The problem was solved considering simple initial conditions, which does not require any previous information about the system, making it clear the robustness of the Hopfield Neural Network method. The pair interaction potential was estimated in the Percus-Yevick (PY) and hypernetted chain (HNC) approximations and a poor agreement, compared with the Lennard-Jones 6-12 potential, was observed for both cases, suggesting the necessity of a more accurate closure relation to describe the system. In this sense, the Hopfield Neural Network together with experimental information provides an alternative approach to solve the Ornstein-Zernike equations, avoiding the limitations imposed by the closure relation.},
  journal = {Brazilian Journal of Physics},
  language = {en},
  number = {5}
}

@article{cybenkoApproximationSuperpositionsSigmoidal1989,
  title = {Approximation by Superpositions of a Sigmoidal Function},
  author = {Cybenko, G.},
  year = {1989},
  month = dec,
  volume = {2},
  pages = {303--314},
  issn = {1435-568X},
  doi = {10.1007/BF02551274},
  abstract = {In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.},
  journal = {Mathematics of Control, Signals and Systems},
  language = {en},
  number = {4}
}

@article{gaoImplementingNelderMeadSimplex2012,
  title = {Implementing the {{Nelder}}-{{Mead}} Simplex Algorithm with~Adaptive Parameters},
  author = {Gao, Fuchang and Han, Lixing},
  year = {2012},
  month = jan,
  volume = {51},
  pages = {259--277},
  issn = {1573-2894},
  doi = {10.1007/s10589-010-9329-3},
  abstract = {In this paper, we first prove that the expansion and contraction steps of the Nelder-Mead simplex algorithm possess a descent property when the objective function is uniformly convex. This property provides some new insights on why the standard Nelder-Mead algorithm becomes inefficient in high dimensions. We then propose an implementation of the Nelder-Mead method in which the expansion, contraction, and shrink parameters depend on the dimension of the optimization problem. Our numerical experiments show that the new implementation outperforms the standard Nelder-Mead method for high dimensional problems.},
  journal = {Computational Optimization and Applications},
  language = {en},
  number = {1}
}

@article{gillanNewMethodSolving1979,
  title = {A New Method of Solving the Liquid Structure Integral Equations},
  author = {Gillan, M. J.},
  year = {1979},
  month = dec,
  volume = {38},
  pages = {1781--1794},
  publisher = {{Taylor \& Francis}},
  issn = {0026-8976},
  doi = {10.1080/00268977900102861},
  abstract = {We present a new method of obtaining numerical solutions to the Percus-Yevick and hypernetted chain equations for liquid structure. The method, which is rapidly convergent and very stable, is a hybrid of the traditional iterative scheme and the Newton-Raphson technique. We show by numerical tests for typical potentials that the method gives well-converged solutions in 20 or 30 iterations even for very high densities. The number of iterations needed is insensitive to the choice of initial estimate, even if this is extremely inaccurate.},
  annotation = {\_eprint: https://doi.org/10.1080/00268977900102861},
  journal = {Molecular Physics},
  number = {6}
}

@inproceedings{glorotDeepSparseRectifier2011,
  title = {Deep {{Sparse Rectifier Neural Networks}}},
  booktitle = {Proceedings of the {{Fourteenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  year = {2011},
  month = jun,
  pages = {315--323},
  publisher = {{JMLR Workshop and Conference Proceedings}},
  issn = {1938-7228},
  abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neu...},
  language = {en}
}

@inproceedings{glorotUnderstandingDifficultyTraining2010,
  title = {Understanding the Difficulty of Training Deep Feedforward Neural Networks},
  booktitle = {Proceedings of the {{Thirteenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Glorot, Xavier and Bengio, Yoshua},
  year = {2010},
  month = mar,
  pages = {249--256},
  publisher = {{JMLR Workshop and Conference Proceedings}},
  issn = {1938-7228},
  abstract = {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental resul...},
  language = {en}
}

@article{goodallCoarsegrainingDesigningLiquids2021,
  title = {Coarse-Graining and Designing Liquids by Combining Machine Learning with Liquid State Theory},
  author = {Goodall, Rhys E. A. and Lee, Alpha A.},
  year = {2021},
  month = jan,
  abstract = {A key challenge for soft materials design and coarse-graining simulations is determining interaction potentials between components that give rise to desired condensed-phase structures. In theory, the Ornstein-Zernike equation provides an elegant framework for solving this inverse problem. Pioneering work in liquid state theory derived analytical closures for the framework. However, these analytical closures are approximations, valid only for specific classes of interaction potentials. In this work, we combine the physics of liquid state theory with deep learning to infer a closure directly from simulation data. The resulting closure is more accurate than commonly used closures across a broad range of interaction potentials. We show for a prototypical inverse design problem, fitting a coarse-grained simulation potential, that our approach leads to significantly improved one-step inversion.},
  archiveprefix = {arXiv},
  eprint = {2004.09114},
  eprinttype = {arxiv},
  journal = {arXiv:2004.09114 [cond-mat, physics:physics]},
  keywords = {Condensed Matter - Soft Condensed Matter,important,Physics - Computational Physics},
  primaryclass = {cond-mat, physics:physics}
}

@article{goodallInferenceUniversalOrnsteinZernike,
  title = {Inference of a {{Universal Ornstein}}-{{Zernike Closure Relationship}} with {{Machine Learning}}},
  author = {Goodall, Rhys E A and Lee, Alpha A},
  pages = {6},
  abstract = {The Ornstein-Zernike framework provides an elegant route for solving the inverse problem of determining a pairwise interaction potential for a liquid given its structure. However, in order to realise the potential of the formalism superior closure relationships are required. Current approximate closure relationships have been shown to have restricted universality and give rise to thermodynamic inconsistencies. In this work rather than attempting to analytically derive a new closure relationship we return to the point of the approximation and investigate whether machine learning can be used to infer a universal closure for the framework directly from simulation data. We show preliminary results that indicate this is a fruitful approach and identify areas for further work.},
  language = {en}
}

@article{goodallMachineLearntApproximations2020,
  title = {Machine Learnt Approximations to the Bridge Function Yield Improved Closures for the {{Ornstein}}-{{Zernike}} Equation},
  author = {Goodall, Rhys E. A. and Lee, Alpha A.},
  year = {2020},
  month = apr,
  abstract = {A key challenge for soft materials design and coarse-graining simulations is determining interaction potentials between components that give rise to desired condensed-phase structures. In theory, the Ornstein-Zernike equation provides an elegant framework for solving this inverse problem. Pioneering work in liquid state theory derived analytical closures for the framework. However, these analytical closures are approximations, valid only for specific classes of interaction potentials. In this work, we combine the physics of liquid state theory with machine learning to infer a closure directly from simulation data. The resulting closure is more accurate than commonly used closures across a broad range of interaction potentials. We show for two examples of a prototypical inverse design problem, fitting a coarse-grained simulation potential, that our approach leads to improved one-step inversion.},
  language = {en}
}

@book{goodfellowDeepLearning2016,
  title = {Deep {{Learning}}},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  month = nov,
  publisher = {{MIT Press}},
  abstract = {An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.``Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.''\textemdash Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.},
  googlebooks = {omivDQAAQBAJ},
  isbn = {978-0-262-33737-3},
  keywords = {Computers / Artificial Intelligence / General,Computers / Computer Science},
  language = {en}
}

@article{hornikApproximationCapabilitiesMultilayer1991,
  title = {Approximation Capabilities of Multilayer Feedforward Networks},
  author = {Hornik, Kurt},
  year = {1991},
  month = jan,
  volume = {4},
  pages = {251--257},
  issn = {0893-6080},
  doi = {10.1016/0893-6080(91)90009-T},
  abstract = {We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp({$\mu$}) performance criteria, for arbitrary finite input environment measures {$\mu$}, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives.},
  journal = {Neural Networks},
  keywords = {() approximation,Activation function,Input environment measure,Multilayer feedforward networks,Smooth approximation,Sobolev spaces,Uniform approximation,Universal approximation capabilities},
  language = {en},
  number = {2}
}

@article{hornikMultilayerFeedforwardNetworks1989,
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  year = {1989},
  month = jan,
  volume = {2},
  pages = {359--366},
  issn = {0893-6080},
  doi = {10.1016/0893-6080(89)90020-8},
  abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
  journal = {Neural Networks},
  keywords = {Back-propagation networks,Feedforward networks,Mapping networks,Network representation capability,Sigma-Pi networks,Squashing functions,Stone-Weierstrass Theorem,Universal approximation},
  language = {en},
  number = {5}
}

@inproceedings{houghZerosGaussianAnalytic2009,
  title = {Zeros of {{Gaussian Analytic Functions}} and {{Determinantal Point Processes}}},
  booktitle = {University {{Lecture Series}}},
  author = {Hough, J. and Krishnapur, Manjunath and Peres, Y. and Vir{\'a}g, B.},
  year = {2009},
  doi = {10.1090/ULECT/051},
  abstract = {The book examines in some depth two important classes of point processes, determinantal processes and 'Gaussian zeros', i.e., zeros of random analytic functions with Gaussian coefficients. These processes share a property of 'point-repulsion', where distinct points are less likely to fall close to each other than in processes, such as the Poisson process, that arise from independent sampling. Nevertheless, the treatment in the book emphasizes the use of independence: for random power series, the independence of coefficients is key; for determinantal processes, the number of points in a domain is a sum of independent indicators, and this yields a satisfying explanation of the central limit theorem (CLT) for this point count. Another unifying theme of the book is invariance of considered point processes under natural transformation groups. The book strives for balance between general theory and concrete examples. On the one hand, it presents a primer on modern techniques on the interface of probability and analysis. On the other hand, a wealth of determinantal processes of intrinsic interest are analyzed; these arise from random spanning trees and eigenvalues of random matrices, as well as from special power series with determinantal zeros. The material in the book formed the basis of a graduate course given at the IAS-Park City Summer School in 2007; the only background knowledge assumed can be acquired in first-year graduate courses in analysis and probability.}
}

@article{kellerIntegralEquationsMachine2019,
  title = {Integral Equations and Machine Learning},
  author = {Keller, Alexander and Dahm, Ken},
  year = {2019},
  month = jul,
  volume = {161},
  pages = {2--12},
  issn = {0378-4754},
  doi = {10.1016/j.matcom.2019.01.010},
  abstract = {As both light transport simulation and reinforcement learning are ruled by the same Fredholm integral equation of the second kind, reinforcement learning techniques may be used for photorealistic image synthesis: Efficiency may be dramatically improved by guiding light transport paths by an approximate solution of the integral equation that is learned during rendering. In the light of the recent advances in reinforcement learning for playing games, we investigate the representation of an approximate solution of an integral equation by artificial neural networks and derive a loss function for that purpose. The resulting Monte Carlo and quasi-Monte Carlo methods train neural networks with standard information instead of linear information and naturally are able to generate an arbitrary number of training samples. The methods are demonstrated for applications in light transport simulation.},
  journal = {Mathematics and Computers in Simulation},
  keywords = {Artificial neural networks,Integral equations,Light transport simulation,Monte Carlo and quasi-Monte Carlo methods,Reinforcement learning},
  language = {en},
  series = {Special Issue on the {{Eleventh International Conference}} on {{Monte Carlo Methods}} and {{Applications}} ({{MCM}} 2017), Held in {{Montreal}}, {{Canada}}, {{July}} 03-07, 2017}
}

@article{kelleyFastSolverOrnstein2004,
  title = {A Fast Solver for the {{Ornstein}}\textendash{{Zernike}} Equations},
  author = {Kelley, C. T. and Pettitt, B. Montgomery},
  year = {2004},
  month = jul,
  volume = {197},
  pages = {491--501},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2003.12.006},
  abstract = {In this paper, we report on the design and analysis of a multilevel method for the solution of the Ornstein\textendash Zernike Equations and related systems of integro-algebraic equations. Our approach is based on an extension of the Atkinson\textendash Brakhage method, with Newton-GMRES used as the coarse mesh solver. We report on several numerical experiments to illustrate the effectiveness of the method. The problems chosen are related to simple short ranged fluids with continuous potentials. Speedups over traditional methods for a given accuracy are reported. The new multilevel method is roughly six times faster than Newton-GMRES and 40 times faster than Picard.},
  journal = {Journal of Computational Physics},
  language = {en},
  number = {2}
}

@article{kingmaAdamMethodStochastic2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2017},
  month = jan,
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  archiveprefix = {arXiv},
  eprint = {1412.6980},
  eprinttype = {arxiv},
  journal = {arXiv:1412.6980 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryclass = {cs}
}

@article{kolafaBridgeFunctionHard2002,
  title = {The Bridge Function of Hard Spheres by Direct Inversion of Computer Simulation Data},
  author = {KOLAFA, JI{\v R}{\'I} and LAB{\'I}K, STANISLAV and MALIJEVSK{\'Y}, ANATOL},
  year = {2002},
  month = aug,
  volume = {100},
  pages = {2629--2640},
  publisher = {{Taylor \& Francis}},
  issn = {0026-8976},
  doi = {10.1080/00268970210136357},
  abstract = {The bridge function of the hard sphere fluid has been calculated from our new highly accurate Monte Carlo and molecular dynamics simulation data on the radial distribution function using the (inverted) Ornstein-Zernike equation. Both the systematic errors (finite size, grid size, tail) and statistical errors are analysed in detail and ways to suppress them are proposed. Uncertainties in the resulting values of B(r) are about 0.001. In contrast with many previous findings the bridge function is both positive and negative.},
  annotation = {\_eprint: https://doi.org/10.1080/00268970210136357},
  journal = {Molecular Physics},
  number = {16}
}

@article{labikEfficientGaussNewtonlikeMethod1994,
  title = {An {{Efficient Gauss}}-{{Newton}}-like {{Method}} for the {{Numerical Solution}} of the {{Ornstein}}-{{Zernike Integral Equation}} for a {{Class}} of {{Fluid Models}}},
  author = {Lab{\'{\i}}k, Stanislav and Posp{\'{\i}}{\v s}il, Roman and Malijevsk{\'y}, Anatol and Smith, William Robert},
  year = {1994},
  month = nov,
  volume = {115},
  pages = {12--21},
  issn = {0021-9991},
  doi = {10.1006/jcph.1994.1174},
  abstract = {A numerical algorithm for solving the Ornstein-Zernike (OZ) integral equation of statistical mechanics is described for the class of fluids composed of molecules with axially symmetric interactions. Since the OZ equation is a nonlinear second-kind Fredholm equation whose key feature for the class of problems of interest is the highly computationally intensive nature of the kernel, the general approach employed in this paper is thus potentially useful for similar problems with this characteristic. The algorithm achieves a high degree of computational efficiency by combining iterative linearization of the most complex portion of the kernel with a combination of Newton-Raphson and Picard iteration methods for the resulting approximate equation. This approach makes the algorithm analogous to the approach of the classical Gauss-Newton method for nonlinear regression, and we call our method the GN algorithm. An example calculation is given illustrating the use of the algorithm for the hard prolate ellipsoid fluid and its results are compared directly with those of the Picard iteration method. The GN algorithm is four to ten times as fast as the Picard method, and we present evidence that it is the most efficient general method currently available.},
  journal = {Journal of Computational Physics},
  language = {en},
  number = {1}
}

@article{labikRapidlyConvergentMethod1985,
  title = {A Rapidly Convergent Method of Solving the {{OZ}} Equation},
  author = {Lab{\'i}k, Stanislav and Malijevsk{\'y}, Anatol and Vo{\v n}ka, Petr},
  year = {1985},
  month = oct,
  volume = {56},
  pages = {709--715},
  publisher = {{Taylor \& Francis}},
  issn = {0026-8976},
  doi = {10.1080/00268978500102651},
  abstract = {A new method is proposed for solving numerically the Ornstein-Zernike equation for systems with a spherically symmetrical pair-potential. The method is based on expansion of the function {$\Gamma$}(r)=r[h(r) - c(r)] in suitable basis functions and on a combination of Newton-Raphson and direct iterations. Tests on the PY and HNC approximations for hard spheres and Lennard-Jones fluid have shown that the proposed method is three to nine times as rapid as the related and so far the most efficient method of Gillan. Other advantages besides the speed are low sensitivity to the choice of initial estimate and a relatively simple computational scheme.},
  annotation = {\_eprint: https://doi.org/10.1080/00268978500102651},
  journal = {Molecular Physics},
  number = {3}
}

@article{llano-restrepoBridgeFunctionCavity1992,
  title = {Bridge Function and Cavity Correlation Function for the {{Lennard}}-{{Jones}} Fluid from Simulation},
  author = {Llano-Restrepo, Mario and Chapman, Walter G.},
  year = {1992},
  month = aug,
  volume = {97},
  pages = {2046--2054},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/1.463142},
  journal = {The Journal of Chemical Physics},
  number = {3}
}

@article{lombaOrnsteinZernikeEquationsSimulation1993,
  title = {Ornstein-{{Zernike}} Equations and Simulation Results for Hard-Sphere Fluids Adsorbed in Porous Media},
  author = {Lomba, Enrique and Given, James A. and Stell, George and Weis, Jean Jacques and Levesque, Dominique},
  year = {1993},
  month = jul,
  volume = {48},
  pages = {233--244},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.48.233},
  abstract = {In this paper we solve the replica Ornstein-Zernike (ROZ) equations in the hypernetted-chain (HNC), Percus-Yevick (PY), and reference Percus-Yevick (RPY) approximations for partly quenched systems. The ROZ equations, which apply to the general class of partly quenched systems, are here applied to a class of models for porous media. These models involve two species of particles: an annealed or equilibrated species, which is used to model the fluid phase, and a quenched or frozen species, whose excluded-volume interactions constitute the matrix in which the fluid is adsorbed. We study two models for the quenched species of particles: a hard-sphere matrix, for which the fluid-fluid, matrix-matrix, and matrix-fluid sphere diameters {$\sigma$}11, {$\sigma$}00, and {$\sigma$}01 are additive, and a matrix of randomly overlapping particles (which still interact with the fluid particle as hard spheres) that gives a ``random'' matrix with interconnected pore structure. For the random-matrix case we study a ratio {$\sigma$}01/{$\sigma$}11 of 2.5, which is a demanding one for the theories. The HNC and RPY results represent significant improvements over the PY result when compared with the Monte Carlo simulations we have generated for this study, with the HNC result yielding the best results overall among those studied. A phenomenological percolating-fluid approximation is also found to be of comparable accuracy to the HNC results over a significant range of matrix and fluid densities. In the hard-sphere matrix case, the RPY is the best of the theories that we have considered.},
  journal = {Physical Review E},
  number = {1}
}

@article{malijevskyBridgeFunctionHard1987,
  title = {The Bridge Function for Hard Spheres},
  author = {Malijevsk{\'y}, Anatol and Lab{\'i}k, Stanislav},
  year = {1987},
  month = feb,
  volume = {60},
  pages = {663--669},
  publisher = {{Taylor \& Francis}},
  issn = {0026-8976},
  doi = {10.1080/00268978700100441},
  abstract = {The paper presents an empirical formula for expressing the bridge function (the sum of elementary graphs) in terms of the interparticle separation and the density. The formulae is fully consistent with the best computer-simulation thermodynamic and structural data for hard spheres in the fluid region. It can serve as both a direct and convenient testing ground for the integral-equation theories of hard spheres and an input to the reference-hypernetted chain approximation for simple fluids.},
  annotation = {\_eprint: https://doi.org/10.1080/00268978700100441},
  journal = {Molecular Physics},
  number = {3}
}

@book{nocedalNumericalOptimization2006,
  title = {Numerical {{Optimization}}},
  author = {Nocedal, Jorge and Wright, S.},
  year = {2006},
  edition = {Second},
  publisher = {{Springer-Verlag}},
  address = {{New York}},
  doi = {10.1007/978-0-387-40065-5},
  abstract = {Numerical Optimization presents a comprehensive and up-to-date description of the most effective methods in continuous optimization. It responds to the growing interest in optimization in engineering, science, and business by focusing on the methods that are best suited to practical problems. For this new edition the book has been thoroughly updated throughout. There are new chapters on nonlinear interior methods and derivative-free methods for optimization, both of which are used widely in practice and the focus of much current research. Because of the emphasis on practical methods, as well as the extensive illustrations and exercises, the book is accessible to a wide audience. It can be used as a graduate text in engineering, operations research, mathematics, computer science, and business. It also serves as a handbook for researchers and practitioners in the field. The authors have strived to produce a text that is pleasant to read, informative, and rigorous - one that reveals both the beautiful nature of the discipline and its practical side.},
  isbn = {978-0-387-30303-1},
  language = {en},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}}
}

@article{peplowAlgorithmsComputationSolutions2006,
  title = {Algorithms for the Computation of Solutions of the {{Ornstein}}-{{Zernike}} Equation},
  author = {Peplow, A. T. and Beardmore, R. E. and Bresme, F.},
  year = {2006},
  month = oct,
  volume = {74},
  pages = {046705},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.74.046705},
  abstract = {We introduce a robust and efficient methodology to solve the Ornstein-Zernike integral equation using the pseudoarc length (PAL) continuation method that reformulates the integral equation in an equivalent but nonstandard form. This enables the computation of solutions in regions where the compressibility experiences large changes or where the existence of multiple solutions and so-called branch points prevents Newton's method from converging. We illustrate the use of the algorithm with a difficult problem that arises in the numerical solution of integral equations, namely the evaluation of the so-called no-solution line of the Ornstein-Zernike hypernetted chain (HNC) integral equation for the Lennard-Jones potential. We are able to use the PAL algorithm to solve the integral equation along this line and to connect physical and nonphysical solution branches (both isotherms and isochores) where appropriate. We also show that PAL continuation can compute solutions within the no-solution region that cannot be computed when Newton and Picard methods are applied directly to the integral equation. While many solutions that we find are new, some correspond to states with negative compressibility and consequently are not physical.},
  journal = {Physical Review E},
  number = {4}
}

@article{rogersNewThermodynamicallyConsistent1984,
  title = {New, Thermodynamically Consistent, Integral Equation for Simple Fluids},
  author = {Rogers, Forrest J. and Young, David A.},
  year = {1984},
  month = aug,
  volume = {30},
  pages = {999--1007},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevA.30.999},
  abstract = {A new integral equation in which the hypernetted-chain and Percus-Yevick approximations are "mixed" as a function of interparticle separation is described. An adjustable parameter {$\alpha$} in the mixing function is used to enforce thermodynamic consistency. For simple 1rn potential fluids, {$\alpha$} is constant for all densities, and the solutions of the integral equations are in very good agreement with Monte Carlo calculations. For the one-component plasma, {$\alpha$} is a slowly varying function of density, but the agreement between calculated solutions and Monte Carlo is also good. This approach has definite advantages over previous thermodynamically consistent equations.},
  journal = {Physical Review A},
  number = {2}
}

@article{rubinsteinOptimizationComputerSimulation1997,
  title = {Optimization of Computer Simulation Models with Rare Events},
  author = {Rubinstein, Reuven Y.},
  year = {1997},
  month = may,
  volume = {99},
  pages = {89--112},
  issn = {0377-2217},
  doi = {10.1016/S0377-2217(96)00385-2},
  abstract = {Discrete event simulation systems (DESS) are widely used in many diverse areas such as computer-communication networks, flexible manufacturing systems, project evaluation and review techniques (PERT), and flow networks. Because of their complexity, such systems are typically analyzed via Monte Carlo simulation methods. This paper deals with optimization of complex computer simulation models involving rare events. A classic example is to find an optimal (s, S) policy in a multi-item, multicommodity inventory system, when quality standards require the backlog probability to be extremely small. Our approach is based on change of the probability measure techniques, also called likelihood ratio (LR) and importance sampling (IS) methods. Unfortunately, for arbitrary probability measures the LR estimators and the resulting optimal solution often tend to be unstable and may have large variances. Therefore, the choice of the corresponding importance sampling distribution and in particular its parameters in an optimal way is an important task. We consider the case where the IS distribution comes from the same parametric family as the original (true) one and use the stochastic counterpart method to handle simulation based optimization models. More specifically, we use a two-stage procedure: at the first stage we identify (estimate) the optimal parameter vector at the IS distribution, while at the second stage we estimate the optimal solution of the underlying constrained optimization problem. Particular emphasis will be placed on estimation of rare events and on integration of the associated performance function into stochastic optimization programs. Supporting numerical results are provided as well.},
  journal = {European Journal of Operational Research},
  keywords = {Inventory,Optimization,Score function,Sensitivity analysis,Simulation},
  language = {en},
  number = {1}
}

@article{schmidtDistillingFreeFormNatural2009,
  title = {Distilling {{Free}}-{{Form Natural Laws}} from {{Experimental Data}}},
  author = {Schmidt, Michael and Lipson, Hod},
  year = {2009},
  month = apr,
  volume = {324},
  pages = {81--85},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1165893},
  abstract = {For centuries, scientists have attempted to identify and document analytical laws that underlie physical phenomena in nature. Despite the prevalence of computing power, the process of finding natural laws and their corresponding equations has resisted automation. A key challenge to finding analytic relations automatically is defining algorithmically what makes a correlation in observed data important and insightful. We propose a principle for the identification of nontriviality. We demonstrated this approach by automatically searching motion-tracking data captured from various physical systems, ranging from simple harmonic oscillators to chaotic double-pendula. Without any prior knowledge about physics, kinematics, or geometry, the algorithm discovered Hamiltonians, Lagrangians, and other laws of geometric and momentum conservation. The discovery rate accelerated as laws found for simpler systems were used to bootstrap explanations for more complex systems, gradually uncovering the ``alphabet'' used to describe those systems. An algorithm has been developed to search for natural laws of physics in large data sets. An algorithm has been developed to search for natural laws of physics in large data sets.},
  chapter = {Report},
  copyright = {American Association for the Advancement of Science},
  journal = {Science},
  language = {en},
  number = {5923},
  pmid = {19342586}
}

@article{scholl-paschingerSelfconsistentOrnsteinZernike2003,
  title = {Self-Consistent {{Ornstein}}\textendash{{Zernike}} Approximation for a Binary Symmetric Fluid Mixture},
  author = {{Sch{\"o}ll-Paschinger}, Elisabeth and Kahl, Gerhard},
  year = {2003},
  month = apr,
  volume = {118},
  pages = {7414--7424},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/1.1557053},
  journal = {The Journal of Chemical Physics},
  number = {16}
}

@article{tangAnalyticalSolutionOrnsteinZernike1995,
  title = {Analytical Solution of the {{Ornstein}}-{{Zernike}} Equation for Mixtures},
  author = {Tang, Yiping and Lu, Benjamin C.-Y.},
  year = {1995},
  month = jan,
  volume = {84},
  pages = {89--103},
  publisher = {{Taylor \& Francis}},
  issn = {0026-8976},
  doi = {10.1080/00268979500100061},
  abstract = {Solution of the Ornstein-Zernike equation under the Percus-Yevick or the mean spherical approximation is presented analytically in a matrix form. The new solution is an extension of the general Ornstein-Zernike solution suggested recently for pure fluids. The development is based on further application of the Hilbert transform and multiple-dimensional space analysis. In addition to the potential matrix, only a hard core correlation function matrix and its inverse are involved in the expression. The solution achieved in this work is explicit and is applicable to any arbitrary potential functions with an additive hard core. The first-order solution for two Yukawa mixtures has been compared with the full solution reported in the literature to serve as an example.},
  annotation = {\_eprint: https://doi.org/10.1080/00268979500100061},
  journal = {Molecular Physics},
  number = {1}
}

@article{torrieMonteCarloCalculation1977,
  title = {Monte {{Carlo}} Calculation of y(r) for the Hard-Sphere Fluid},
  author = {Torrie, G. and Patey, G. N.},
  year = {1977},
  month = dec,
  volume = {34},
  pages = {1623--1628},
  publisher = {{Taylor \& Francis}},
  issn = {0026-8976},
  doi = {10.1080/00268977700102821},
  abstract = {The function y(r) = exp {$\beta$}u(r)g(r) is calculated for hard spheres in the region r {$<$} {$\sigma$} using umbrella-sampling Monte Carlo techniques. The resulting values are found to be well represented over the entire range 0 {$<$} r {$<$} {$\sigma$} by a simple function proposed by Grundke and Henderson.},
  annotation = {\_eprint: https://doi.org/10.1080/00268977700102821},
  journal = {Molecular Physics},
  number = {6}
}

@article{tsedneeClosureOrnsteinZernikeEquation2019,
  title = {Closure for the {{Ornstein}}-{{Zernike}} Equation with Pressure and Free Energy Consistency},
  author = {Tsednee, Tsogbayar and Luchko, Tyler},
  year = {2019},
  month = mar,
  volume = {99},
  pages = {032130},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.99.032130},
  abstract = {The Ornstein-Zernike (OZ) integral equation theory is a powerful approach to simple liquids due to its low computational cost and the fact that, when combined with an appropriate closure equation, the theory is thermodynamically complete. However, approximate closures proposed to date exhibit pressure or free energy inconsistencies that produce inaccurate or ambiguous results, limiting the usefulness of the Ornstein-Zernike approach. To address this problem, we combine methods to enforce both pressure and free energy consistency to create a new closure approximation and test it for a single-component Lennard-Jones fluid. The closure is a simple power series in the direct and total correlation functions for which we have derived analytical formulas for the excess Helmholtz free energy and chemical potential. These expressions contain a partial molar volumelike term, similar to excess chemical potential correction terms recently developed. Using our bridge approximation, we have calculated the pressure, Helmholtz free energy, and chemical potential for the Lennard-Jones fluid using the Kirkwood charging, thermodynamic integration techniques, and analytic expressions. These results are compared with those from the hypernetted chain equation and the Verlet-modified closure against Monte Carlo and equations-of-state data for reduced densities of {$\rho{_\ast}<$}1 and temperatures of T{${_\ast}$}=1.5, 2.74, and 5. Our closure shows consistency among all thermodynamic paths, except for one expression of the Gibbs-Duhem relation, whereas the hypernetted chain equation and the Verlet-modified closure exhibit consistency between only a few relations. Accuracy of the closure is comparable to the Verlet-modified closure and a significant improvement to results obtained from the hypernetted chain equation.},
  journal = {Physical Review E},
  number = {3}
}

@article{vompeBridgeFunctionExpansion1994,
  title = {The Bridge Function Expansion and the Self-consistency Problem of the {{Ornstein}}\textendash{{Zernike}} Equation Solution},
  author = {Vompe, A. G. and Martynov, G. A.},
  year = {1994},
  month = apr,
  volume = {100},
  pages = {5249--5258},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/1.467189},
  journal = {The Journal of Chemical Physics},
  number = {7}
}

@article{zerahEfficientNewtonMethod1985,
  title = {An Efficient Newton's Method for the Numerical Solution of Fluid Integral Equations},
  author = {Zerah, Gilles},
  year = {1985},
  month = nov,
  volume = {61},
  pages = {280--285},
  issn = {0021-9991},
  doi = {10.1016/0021-9991(85)90087-7},
  abstract = {We propose a stable, straightforward algorithm for the numerical solution of integral equations for fluid pair distribution functions. The integral equation is not solved by Picard's standard iterative procedure but by Newton's method of solution of non-linear equations. The large matrix appearing in Newton's method is inverted by a conjugate gradient procedure used as a rapidly converging iterative method.},
  journal = {Journal of Computational Physics},
  language = {en},
  number = {2}
}

@article{zerahSelfConsistentIntegral1986,
  title = {Self-consistent Integral Equations for Fluid Pair Distribution Functions: {{Another}} Attempt},
  shorttitle = {Self-consistent Integral Equations for Fluid Pair Distribution Functions},
  author = {Zerah, Gilles and Hansen, Jean-Pierre},
  year = {1986},
  month = feb,
  volume = {84},
  pages = {2336--2343},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/1.450397},
  journal = {The Journal of Chemical Physics},
  number = {4}
}


